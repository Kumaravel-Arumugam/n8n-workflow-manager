{
  "name": "Job Market Analysis Engine",
  "nodes": [
    {
      "parameters": {
        "workflowInputs": {
          "values": [
            { "name": "telegram_chat_id", "type": "number" },
            { "name": "role_name" }
          ]
        }
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [-688, 224],
      "id": "trigger-node",
      "name": "Analysis Trigger"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT * FROM job_postings WHERE chat_id = {{ $json.telegram_chat_id }} AND role = '{{ $json.role_name }}' ORDER BY scraped_date DESC;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [-464, 224],
      "id": "fetch-jobs-node",
      "name": "Fetch Job Postings",
      "credentials": {
        "postgres": {
          "id": "huv0oVp6gAOYZofK",
          "name": "job_market_intelligence"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [
            {
              "id": "check-data-exists",
              "leftValue": "={{ $input.all().length }}",
              "rightValue": 0,
              "operator": { "type": "number", "operation": "gt" }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [-240, 224],
      "id": "data-check-node",
      "name": "Has Data?"
    },
    {
      "parameters": {
        "language": "pythonNative",
        "pythonCode": "import pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\nimport io\nimport base64\nimport re\nfrom datetime import datetime\nfrom collections import Counter\nfrom itertools import combinations\nimport json\n\njobs = _items\nif not jobs:\n    empty_manifest = [\n        {\"chart_id\": \"chart_1\", \"chart_name\": \"Skill Demand\", \"chart_type\": \"Horizontal Bar\", \"generated\": False, \"reason\": \"No job data received\"},\n        {\"chart_id\": \"chart_2\", \"chart_name\": \"Experience Distribution\", \"chart_type\": \"Bar\", \"generated\": False, \"reason\": \"No job data received\"},\n        {\"chart_id\": \"chart_3\", \"chart_name\": \"Skill Category Distribution\", \"chart_type\": \"Pie\", \"generated\": False, \"reason\": \"No job data received\"},\n        {\"chart_id\": \"chart_4\", \"chart_name\": \"Experience Demand Curve\", \"chart_type\": \"Area\", \"generated\": False, \"reason\": \"No job data received\"}\n    ]\n    return [{'error': 'No job data received', 'has_data': False, 'chart1_base64': '', 'chart2_base64': '', 'chart3_base64': '', 'chart4_base64': '', 'chart1_caption': '', 'chart2_caption': '', 'chart3_caption': '', 'chart4_caption': '', 'raw_analysis': '{}', 'chart_manifest': json.dumps(empty_manifest)}]\n\nrecords = [item.get('json', item) if isinstance(item, dict) else item for item in jobs]\ndf = pd.DataFrame(records)\n\nif 'job_id' in df.columns:\n    original_count = len(df)\n    df = df.drop_duplicates(subset=['job_id'])\n    duplicates_removed = original_count - len(df)\nelse:\n    duplicates_removed = 0\n\ntotal_jobs = len(df)\nrole_name = df['role'].iloc[0] if 'role' in df.columns and len(df) > 0 else 'Unknown Role'\n\nSKILL_NORMALIZATION = {\n    'powerbi': 'Power BI', 'power bi': 'Power BI', 'power-bi': 'Power BI', 'pbi': 'Power BI',\n    'postgres': 'PostgreSQL', 'postgresql': 'PostgreSQL', 'pg': 'PostgreSQL',\n    'gcp': 'GCP', 'google cloud platform': 'GCP', 'google cloud': 'GCP',\n    'aws': 'AWS', 'amazon web services': 'AWS', 'azure': 'Azure', 'microsoft azure': 'Azure',\n    'sql': 'SQL', 'mysql': 'MySQL', 'mssql': 'SQL Server', 'sql server': 'SQL Server',\n    'python': 'Python', 'python3': 'Python', 'py': 'Python',\n    'javascript': 'JavaScript', 'js': 'JavaScript', 'node.js': 'Node.js', 'nodejs': 'Node.js',\n    'java': 'Java', 'excel': 'Excel', 'ms excel': 'Excel', 'microsoft excel': 'Excel',\n    'tableau': 'Tableau', 'machine learning': 'Machine Learning', 'ml': 'Machine Learning',\n    'ai': 'AI', 'artificial intelligence': 'AI', 'data science': 'Data Science', 'datascience': 'Data Science',\n    'data analysis': 'Data Analysis', 'data analytics': 'Data Analytics', 'etl': 'ETL',\n    'agile': 'Agile', 'scrum': 'Scrum', 'jira': 'Jira', 'confluence': 'Confluence',\n    'docker': 'Docker', 'kubernetes': 'Kubernetes', 'k8s': 'Kubernetes',\n    'git': 'Git', 'github': 'GitHub', 'gitlab': 'GitLab', 'spark': 'Spark', 'apache spark': 'Spark', 'hadoop': 'Hadoop',\n    'bigquery': 'BigQuery', 'snowflake': 'Snowflake', 'databricks': 'Databricks',\n    'salesforce': 'Salesforce', 'crm': 'CRM', 'erp': 'ERP', 'sap': 'SAP', 'oracle': 'Oracle',\n    'communication': 'Communication', 'collaboration': 'Collaboration',\n    'project management': 'Project Management', 'pm': 'Project Management',\n    'business analyst': 'Business Analysis', 'business analysis': 'Business Analysis',\n    'process mapping': 'Process Mapping', 'business processes': 'Business Processes',\n    'api': 'API', 'linux': 'Linux', 'ci/cd': 'CI/CD', 'mongodb': 'MongoDB', 'nosql': 'NoSQL',\n    'kafka': 'Kafka', 'data warehousing': 'Data Warehousing', 'data engineering': 'Data Engineering',\n    'data quality': 'Data Quality', 'advanced analytics': 'Advanced Analytics', 'analytics': 'Analytics',\n    'analytical': 'Analytical', 'finance': 'Finance', 'operations': 'Operations',\n    'management': 'Management', 'compliance': 'Compliance', 'design': 'Design'\n}\n\nSKILL_CATEGORIES = {\n    'Technical / Programming': ['Python', 'Java', 'JavaScript', 'Node.js', 'SQL', 'MySQL', 'PostgreSQL', 'SQL Server', 'MongoDB', 'NoSQL', 'API', 'Linux', 'CI/CD', 'Git', 'GitHub', 'GitLab'],\n    'Data & Analytics': ['Data Analysis', 'Data Analytics', 'Data Science', 'Machine Learning', 'AI', 'ETL', 'Data Warehousing', 'Data Engineering', 'Data Quality', 'Advanced Analytics', 'Analytics', 'Analytical', 'Business Analysis'],\n    'Cloud & Infrastructure': ['AWS', 'Azure', 'GCP', 'Docker', 'Kubernetes', 'Spark', 'Hadoop', 'Kafka', 'BigQuery', 'Snowflake', 'Databricks'],\n    'Business / Process': ['Business Processes', 'Process Mapping', 'Project Management', 'Finance', 'Operations', 'Management', 'Compliance'],\n    'Tools & Platforms': ['Excel', 'Tableau', 'Power BI', 'Jira', 'Confluence', 'Salesforce', 'CRM', 'ERP', 'SAP', 'Oracle'],\n    'Soft / Collaboration': ['Communication', 'Collaboration', 'Agile', 'Scrum', 'Design']\n}\n\ndef get_skill_category(skill):\n    for category, skills in SKILL_CATEGORIES.items():\n        if skill in skills:\n            return category\n    return 'Other'\n\nknown_skills = list(set(SKILL_NORMALIZATION.keys()))\n\ndef parse_skills(skill_string):\n    if pd.isna(skill_string) or not str(skill_string).strip():\n        return []\n    s = str(skill_string).lower().strip()\n    found_skills = []\n    remaining = s\n    for skill in sorted(known_skills, key=len, reverse=True):\n        if skill in remaining:\n            normalized = SKILL_NORMALIZATION.get(skill, skill.title())\n            if normalized not in found_skills:\n                found_skills.append(normalized)\n            remaining = remaining.replace(skill, ' ')\n    leftover = [w.strip() for w in remaining.split() if len(w.strip()) > 3 and w.strip() not in ['yrs', 'years', 'the', 'and', 'for', 'with']]\n    for word in leftover[:3]:\n        if word.title() not in found_skills:\n            found_skills.append(word.title())\n    return found_skills\n\ndef parse_experience(exp_string):\n    if pd.isna(exp_string) or not str(exp_string).strip():\n        return None\n    s = str(exp_string).lower().strip()\n    match = re.search(r'(\\\\d+)\\\\s*[-\\\\u2013]\\\\s*(\\\\d+)', s)\n    if match:\n        return (int(match.group(1)) + int(match.group(2))) / 2\n    match = re.search(r'(\\\\d+)', s)\n    return int(match.group(1)) if match else None\n\ndef parse_experience_range(exp_string):\n    if pd.isna(exp_string) or not str(exp_string).strip():\n        return None\n    s = str(exp_string).lower().strip()\n    match = re.search(r'(\\\\d+)\\\\s*[-\\\\u2013]\\\\s*(\\\\d+)', s)\n    if match:\n        min_exp = int(match.group(1))\n        max_exp = int(match.group(2))\n        if max_exp >= min_exp and max_exp <= 25:\n            return (min_exp, max_exp)\n        elif max_exp < min_exp:\n            return (max_exp, min_exp)\n        else:\n            return (min_exp, min(max_exp, 25))\n    match = re.search(r'(\\\\d+)\\\\s*\\\\+?', s)\n    if match:\n        val = int(match.group(1))\n        if '+' in s:\n            return (val, min(val + 5, 25))\n        return (val, val)\n    return None\n\ndata_quality = {\n    'total_raw': len(records), 'total_unique': total_jobs, 'duplicates_removed': duplicates_removed,\n    'has_description': int(df['description'].notna().sum()),\n    'has_skills': int(df['skills'].notna().sum()),\n    'has_experience': int(df['experience'].notna().sum()),\n    'has_salary': int((df['salary'].notna() & (df['salary'] != '')).sum()) if 'salary' in df.columns else 0,\n    'companies_count': int(df['company'].nunique()) if 'company' in df.columns else 0,\n    'locations_count': int(df['location'].nunique()) if 'location' in df.columns else 0\n}\ndata_quality['completeness'] = round((data_quality['has_description'] + data_quality['has_skills'] + data_quality['has_experience']) / (total_jobs * 3) * 100, 1) if total_jobs > 0 else 0\n\nif total_jobs >= 20 and data_quality['completeness'] >= 80:\n    quality_grade = \"HIGH\"\n    quality_desc = \"Robust dataset suitable for comprehensive analysis\"\nelif total_jobs >= 10 and data_quality['completeness'] >= 60:\n    quality_grade = \"MEDIUM\"\n    quality_desc = \"Adequate data for directional insights\"\nelse:\n    quality_grade = \"LOW\"\n    quality_desc = \"Limited data; findings are indicative only\"\n\nall_skills = []\nskills_per_job = []\nfor skills_str in df['skills'].dropna():\n    parsed = parse_skills(skills_str)\n    all_skills.extend(parsed)\n    skills_per_job.append(parsed)\n\nskill_counts = Counter(all_skills)\ntop_skills = skill_counts.most_common(15)\ntotal_skill_mentions = sum(skill_counts.values())\ncore_skills = [s for s, c in top_skills[:5]]\nsecondary_skills = [s for s, c in top_skills[5:10]]\n\nskill_dominance = {}\nif total_skill_mentions > 0:\n    top1_count = top_skills[0][1] if len(top_skills) >= 1 else 0\n    top3_count = sum(c for s, c in top_skills[:3])\n    top5_count = sum(c for s, c in top_skills[:5])\n    long_tail_count = sum(c for s, c in top_skills[5:])\n    skill_dominance = {\n        'top1_skill': top_skills[0][0] if len(top_skills) >= 1 else None,\n        'top1_share': round(top1_count / total_skill_mentions * 100, 1),\n        'top3_share': round(top3_count / total_skill_mentions * 100, 1),\n        'top5_share': round(top5_count / total_skill_mentions * 100, 1),\n        'long_tail_share': round(long_tail_count / total_skill_mentions * 100, 1),\n        'dominance_ratio': round(top5_count / max(long_tail_count, 1), 2),\n        'total_unique_skills': len(skill_counts),\n        'total_skill_mentions': total_skill_mentions\n    }\n\ncategory_counts = Counter()\nfor skill, count in skill_counts.items():\n    cat = get_skill_category(skill)\n    category_counts[cat] += count\n\ncategory_distribution = {}\nif total_skill_mentions > 0:\n    category_distribution = {cat: {'count': count, 'percentage': round(count / total_skill_mentions * 100, 1)} for cat, count in category_counts.most_common()}\n\npair_counts = Counter()\nfor job_skills in skills_per_job:\n    if len(job_skills) >= 2:\n        for pair in combinations(sorted(set(job_skills)), 2):\n            pair_counts[pair] += 1\ntop_pairs = pair_counts.most_common(10)\nskill_cooccurrence = [{'pair': f\"{p[0]} + {p[1]}\", 'count': count, 'percentage': round(count / max(len(skills_per_job), 1) * 100, 1)} for p, count in top_pairs if count >= 2]\n\nexp_values = [parse_experience(e) for e in df['experience'].dropna()]\nexp_values = [e for e in exp_values if e is not None]\nexp_dist = {}\ndominant_level = \"N/A\"\nif exp_values:\n    exp_series = pd.Series(exp_values)\n    bins = [0, 2, 5, 8, 12, 25]\n    labels = ['0-2 yrs', '3-5 yrs', '6-8 yrs', '9-12 yrs', '12+ yrs']\n    exp_binned = pd.cut(exp_series, bins=bins, labels=labels, right=True)\n    exp_dist = exp_binned.value_counts().to_dict()\n    exp_dist = {str(k): int(v) for k, v in exp_dist.items() if v > 0}\n    if exp_dist:\n        dominant_level = max(exp_dist, key=exp_dist.get)\n\nexp_ranges = [parse_experience_range(e) for e in df['experience'].dropna()]\nexp_ranges = [e for e in exp_ranges if e is not None]\n\nexperience_range_analytics = {'has_range_data': False, 'ranges_parsed': 0, 'min_experience_observed': None, 'max_experience_observed': None, 'peak_demand_year': None, 'peak_demand_count': 0, 'dominant_band': None, 'avg_range_width': None, 'experience_flexibility': None, 'year_demand_density': {}}\n\nif len(exp_ranges) >= 1:\n    experience_range_analytics['has_range_data'] = True\n    experience_range_analytics['ranges_parsed'] = len(exp_ranges)\n    all_mins = [r[0] for r in exp_ranges]\n    all_maxs = [r[1] for r in exp_ranges]\n    experience_range_analytics['min_experience_observed'] = min(all_mins)\n    experience_range_analytics['max_experience_observed'] = max(all_maxs)\n    year_demand = Counter()\n    for min_exp, max_exp in exp_ranges:\n        for year in range(min_exp, max_exp + 1):\n            if year <= 25:\n                year_demand[year] += 1\n    experience_range_analytics['year_demand_density'] = {str(year): count for year, count in sorted(year_demand.items())}\n    if year_demand:\n        peak_year = max(year_demand, key=year_demand.get)\n        experience_range_analytics['peak_demand_year'] = peak_year\n        experience_range_analytics['peak_demand_count'] = year_demand[peak_year]\n    if year_demand:\n        peak = experience_range_analytics['peak_demand_year']\n        if peak <= 2:\n            experience_range_analytics['dominant_band'] = \"Entry Level (0-2 yrs)\"\n        elif peak <= 5:\n            experience_range_analytics['dominant_band'] = \"Early Career (3-5 yrs)\"\n        elif peak <= 8:\n            experience_range_analytics['dominant_band'] = \"Mid Career (6-8 yrs)\"\n        elif peak <= 12:\n            experience_range_analytics['dominant_band'] = \"Senior (9-12 yrs)\"\n        else:\n            experience_range_analytics['dominant_band'] = \"Expert (12+ yrs)\"\n    range_widths = [max_exp - min_exp for min_exp, max_exp in exp_ranges]\n    avg_width = sum(range_widths) / len(range_widths)\n    experience_range_analytics['avg_range_width'] = round(avg_width, 1)\n    if avg_width <= 2:\n        experience_range_analytics['experience_flexibility'] = \"NARROW\"\n    elif avg_width <= 5:\n        experience_range_analytics['experience_flexibility'] = \"MODERATE\"\n    else:\n        experience_range_analytics['experience_flexibility'] = \"FLEXIBLE\"\n\ntitles = df['title'].dropna().unique().tolist()[:10]\ncompanies = df['company'].dropna().unique().tolist()[:8]\nlocations = df['location'].dropna().unique().tolist()[:5]\ntitle_variance = len(titles)\nif title_variance > 5:\n    title_clarity = \"LOW\"\nelif title_variance > 2:\n    title_clarity = \"MEDIUM\"\nelse:\n    title_clarity = \"HIGH\"\n\nskill_sets = [set(skills) for skills in skills_per_job if len(skills) > 0]\navg_similarity = 0\nif len(skill_sets) > 1:\n    sims = []\n    for i in range(len(skill_sets)-1):\n        intersection = len(skill_sets[i] & skill_sets[i+1])\n        union = len(skill_sets[i] | skill_sets[i+1])\n        if union > 0:\n            sims.append(intersection / union)\n    avg_similarity = float(np.mean(sims)) if sims else 0\nif avg_similarity > 0.4:\n    consistency = \"HIGH\"\nelif avg_similarity > 0.2:\n    consistency = \"MEDIUM\"\nelse:\n    consistency = \"LOW\"\n\nlimitations = []\nif total_jobs < 10:\n    limitations.append(\"Small sample size - findings are directional only\")\nif data_quality['completeness'] < 60:\n    limitations.append(\"Low data completeness - some fields missing\")\nif len(skill_counts) < 5:\n    limitations.append(\"Limited skill variety detected\")\nif len(exp_values) < 3 and len(exp_ranges) < 3:\n    limitations.append(\"Insufficient experience data for patterns\")\n\ncan_generate_charts = total_jobs >= 3\nchart1_condition = can_generate_charts and len(top_skills) >= 3\nchart2_condition = can_generate_charts and len(exp_dist) >= 2\nchart3_condition = can_generate_charts and len(category_distribution) >= 3\nchart4_condition = can_generate_charts and experience_range_analytics['has_range_data'] and len(experience_range_analytics['year_demand_density']) >= 2\n\nchart_manifest = [\n    {\"chart_id\": \"chart_1\", \"chart_name\": \"Skill Demand\", \"chart_type\": \"Horizontal Bar\", \"generated\": chart1_condition, \"reason\": None if chart1_condition else (\"Insufficient postings\" if total_jobs < 3 else \"Fewer than 3 skills\")},\n    {\"chart_id\": \"chart_2\", \"chart_name\": \"Experience Distribution\", \"chart_type\": \"Bar\", \"generated\": chart2_condition, \"reason\": None if chart2_condition else (\"Insufficient postings\" if total_jobs < 3 else \"Fewer than 2 experience bins\")},\n    {\"chart_id\": \"chart_3\", \"chart_name\": \"Skill Category Distribution\", \"chart_type\": \"Pie\", \"generated\": chart3_condition, \"reason\": None if chart3_condition else (\"Insufficient postings\" if total_jobs < 3 else \"Fewer than 3 categories\")},\n    {\"chart_id\": \"chart_4\", \"chart_name\": \"Experience Demand Curve\", \"chart_type\": \"Area\", \"generated\": chart4_condition, \"reason\": None if chart4_condition else (\"Insufficient postings\" if total_jobs < 3 else \"No parseable experience ranges\" if not experience_range_analytics['has_range_data'] else \"Fewer than 2 years with demand\")}\n]\n\nchart1_base64 = \"\"\nchart2_base64 = \"\"\nchart3_base64 = \"\"\nchart4_base64 = \"\"\n\nplt.style.use(\"dark_background\")\nbg_color, text_color = \"#0a0e1a\", \"#f0f0f0\"\n\nif chart1_condition:\n    fig, ax = plt.subplots(figsize=(12, 7), dpi=150)\n    fig.patch.set_facecolor(bg_color)\n    ax.set_facecolor(bg_color)\n    chart_skills = top_skills[:12]\n    skills_labels = [s[0] for s in chart_skills]\n    skills_values = [s[1] for s in chart_skills]\n    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(skills_labels)))\n    bars = ax.barh(skills_labels[::-1], skills_values[::-1], color=colors[::-1], edgecolor='white', linewidth=0.5)\n    ax.set_xlabel('Frequency', color=text_color, fontsize=12, fontweight='600')\n    ax.set_title(f'Skill Demand - {role_name}', color=text_color, fontsize=16, fontweight='bold', pad=20)\n    ax.tick_params(colors=text_color, labelsize=10)\n    ax.grid(axis='x', color='#1a1f2e', linestyle='-', linewidth=0.6, alpha=0.6)\n    for bar, val in zip(bars, skills_values[::-1]):\n        ax.text(bar.get_width() + 0.3, bar.get_y() + bar.get_height()/2, str(val), va='center', color=text_color, fontsize=10)\n    plt.tight_layout()\n    buffer = io.BytesIO()\n    plt.savefig(buffer, format=\"png\", bbox_inches=\"tight\", facecolor=bg_color, dpi=150)\n    buffer.seek(0)\n    chart1_base64 = base64.b64encode(buffer.read()).decode(\"utf-8\")\n    buffer.close()\n    plt.close(fig)\n\nif chart2_condition:\n    fig, ax = plt.subplots(figsize=(10, 6), dpi=150)\n    fig.patch.set_facecolor(bg_color)\n    ax.set_facecolor(bg_color)\n    exp_labels = list(exp_dist.keys())\n    exp_vals = list(exp_dist.values())\n    colors = ['#00d4ff', '#00ff88', '#ffc107', '#ff6b6b', '#b388ff'][:len(exp_labels)]\n    bars = ax.bar(exp_labels, exp_vals, color=colors, edgecolor='white', linewidth=0.5)\n    ax.set_xlabel('Experience Level', color=text_color, fontsize=12, fontweight='600')\n    ax.set_ylabel('Postings', color=text_color, fontsize=12, fontweight='600')\n    ax.set_title(f'Experience Distribution - {role_name}', color=text_color, fontsize=16, fontweight='bold', pad=20)\n    ax.tick_params(colors=text_color, labelsize=10)\n    ax.grid(axis='y', color='#1a1f2e', linestyle='-', linewidth=0.6, alpha=0.6)\n    for bar, val in zip(bars, exp_vals):\n        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2, str(val), ha='center', color=text_color, fontsize=11, fontweight='bold')\n    plt.tight_layout()\n    buffer = io.BytesIO()\n    plt.savefig(buffer, format=\"png\", bbox_inches=\"tight\", facecolor=bg_color, dpi=150)\n    buffer.seek(0)\n    chart2_base64 = base64.b64encode(buffer.read()).decode(\"utf-8\")\n    buffer.close()\n    plt.close(fig)\n\nif chart3_condition:\n    fig, ax = plt.subplots(figsize=(10, 7), dpi=150)\n    fig.patch.set_facecolor(bg_color)\n    ax.set_facecolor(bg_color)\n    cat_labels = list(category_distribution.keys())[:6]\n    cat_values = [category_distribution[c]['count'] for c in cat_labels]\n    cat_colors = ['#00d4ff', '#00ff88', '#ffc107', '#ff6b6b', '#b388ff', '#ff9966'][:len(cat_labels)]\n    wedges, texts, autotexts = ax.pie(cat_values, labels=cat_labels, autopct='%1.0f%%', colors=cat_colors, wedgeprops={'edgecolor': 'white', 'linewidth': 1.5}, textprops={'color': text_color, 'fontsize': 10}, pctdistance=0.75)\n    for autotext in autotexts:\n        autotext.set_color('white')\n        autotext.set_fontweight('bold')\n    ax.set_title(f'Skill Categories - {role_name}', color=text_color, fontsize=16, fontweight='bold', pad=20)\n    plt.tight_layout()\n    buffer = io.BytesIO()\n    plt.savefig(buffer, format=\"png\", bbox_inches=\"tight\", facecolor=bg_color, dpi=150)\n    buffer.seek(0)\n    chart3_base64 = base64.b64encode(buffer.read()).decode(\"utf-8\")\n    buffer.close()\n    plt.close(fig)\n\nif chart4_condition:\n    fig, ax = plt.subplots(figsize=(12, 6), dpi=150)\n    fig.patch.set_facecolor(bg_color)\n    ax.set_facecolor(bg_color)\n    year_data = experience_range_analytics['year_demand_density']\n    years = [int(y) for y in year_data.keys()]\n    counts = list(year_data.values())\n    ax.fill_between(years, counts, alpha=0.4, color='#00d4ff')\n    ax.plot(years, counts, color='#00d4ff', linewidth=2.5, marker='o', markersize=6, markerfacecolor='white', markeredgecolor='#00d4ff')\n    peak_year = experience_range_analytics['peak_demand_year']\n    peak_count = experience_range_analytics['peak_demand_count']\n    ax.scatter([peak_year], [peak_count], s=150, color='#ffc107', zorder=5, edgecolor='white', linewidth=2)\n    ax.annotate(f'Peak: {peak_year} yrs', xy=(peak_year, peak_count), xytext=(peak_year + 1, peak_count + 0.5), fontsize=10, color='#ffc107', fontweight='bold', arrowprops=dict(arrowstyle='->', color='#ffc107', lw=1.5))\n    ax.set_xlabel('Years of Experience', color=text_color, fontsize=12, fontweight='600')\n    ax.set_ylabel('Job Postings Covering This Year', color=text_color, fontsize=12, fontweight='600')\n    ax.set_title(f'Experience Demand Curve - {role_name}', color=text_color, fontsize=16, fontweight='bold', pad=20)\n    ax.tick_params(colors=text_color, labelsize=10)\n    ax.grid(axis='both', color='#1a1f2e', linestyle='-', linewidth=0.6, alpha=0.6)\n    ax.set_xlim(min(years) - 0.5, max(years) + 0.5)\n    ax.set_ylim(0, max(counts) * 1.15)\n    plt.tight_layout()\n    buffer = io.BytesIO()\n    plt.savefig(buffer, format=\"png\", bbox_inches=\"tight\", facecolor=bg_color, dpi=150)\n    buffer.seek(0)\n    chart4_base64 = base64.b64encode(buffer.read()).decode(\"utf-8\")\n    buffer.close()\n    plt.close(fig)\n\nraw_analysis = {\n    'role_name': role_name, 'total_jobs': total_jobs, 'data_quality': data_quality,\n    'quality_grade': quality_grade, 'quality_desc': quality_desc,\n    'core_skills': core_skills, 'secondary_skills': secondary_skills,\n    'skill_counts': dict(top_skills[:10]), 'experience_distribution': exp_dist,\n    'dominant_experience': dominant_level, 'titles': titles[:5], 'title_clarity': title_clarity,\n    'companies': companies[:5], 'locations': locations[:3],\n    'market_consistency': consistency, 'similarity_score': round(avg_similarity * 100, 1),\n    'skills_normalized': True, 'skill_dominance': skill_dominance,\n    'skill_categories': category_distribution, 'skill_cooccurrence': skill_cooccurrence[:5],\n    'limitations': limitations, 'has_limitations': len(limitations) > 0,\n    'experience_range_analytics': experience_range_analytics\n}\n\nchart1_caption = f\"*üìä Skill Demand - {role_name}*\\n\\n_Top skills from {total_jobs} postings._\\n\\n*Core:* {', '.join(core_skills[:3])}\" if chart1_base64 else \"\"\nchart2_caption = f\"*üìà Experience Distribution - {role_name}*\\n\\n_Most demand: {dominant_level}_\" if chart2_base64 else \"\"\nchart3_caption = f\"*üè∑Ô∏è Skill Categories - {role_name}*\\n\\n_Distribution across {len(category_distribution)} categories._\" if chart3_base64 else \"\"\nchart4_caption = f\"*üìâ Experience Demand Curve - {role_name}*\\n\\n_Peak demand at {experience_range_analytics['peak_demand_year']} years._\\n_Flexibility: {experience_range_analytics['experience_flexibility']}_\" if chart4_base64 else \"\"\n\nreturn [{\n    'raw_analysis': json.dumps(raw_analysis),\n    'chart_manifest': json.dumps(chart_manifest),\n    'role_name': role_name, 'total_jobs': total_jobs,\n    'chart1_base64': chart1_base64, 'chart1_caption': chart1_caption,\n    'chart2_base64': chart2_base64, 'chart2_caption': chart2_caption,\n    'chart3_base64': chart3_base64, 'chart3_caption': chart3_caption,\n    'chart4_base64': chart4_base64, 'chart4_caption': chart4_caption,\n    'has_data': True\n}]\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [48, 96],
      "id": "data-processor-node",
      "name": "Data Processor (Python)"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are generating a Job Market Intelligence report.\n\n**ANALYSIS DATA (AUTHORITATIVE):**\n{{ $json.raw_analysis }}\n\n**CHART MANIFEST (AUTHORITATIVE):**\n{{ $json.chart_manifest }}\n\n**REPORT STRUCTURE (MANDATORY):**\n\n*üìä DATA QUALITY ASSESSMENT*\n\nState from data_quality:\n- total_unique postings: [exact number]\n- completeness: [exact percentage]%\n- quality_grade: [HIGH/MEDIUM/LOW]\n- quality_desc: [exact description]\n\nIf has_limitations is true, list each limitation.\n\n---\n\n*üìå SECTION A: ROLE REALITY CHECK*\n\nUsing titles, title_clarity, companies, locations:\n- State title count and clarity level\n- List companies hiring\n- List locations\n\n---\n\n*üìä SECTION B: SKILL DEMAND SIGNAL*\n\nUsing skill_dominance and skill_categories:\n- State top1_skill with top1_share percentage\n- State top3_share and top5_share\n- Identify dominant category\n- List skill pairs from skill_cooccurrence\n\nCHART REFERENCE:\n- Check chart_manifest for chart_1 (Skill Demand)\n- If generated: true ‚Üí \"_üìà Skill Demand chart attached._\"\n- If generated: false ‚Üí \"_Chart not generated: [reason]_\"\n\n---\n\n*üìà SECTION C: EXPERIENCE PATTERN*\n\nUsing experience_distribution, dominant_experience, AND experience_range_analytics:\n\nIf experience_range_analytics.has_range_data is true:\n- State min_experience_observed and max_experience_observed\n- State peak_demand_year and peak_demand_count\n- State dominant_band\n- State experience_flexibility (NARROW/MODERATE/FLEXIBLE)\n- Explain what flexibility means for candidates\n\nCHART REFERENCES:\n- Check chart_manifest for chart_2 (Experience Distribution)\n- Check chart_manifest for chart_4 (Experience Demand Curve)\n- For each: if generated ‚Üí attach message, else ‚Üí state reason\n\n---\n\n*‚öñÔ∏è SECTION D: MARKET CONSISTENCY*\n\nUsing market_consistency and similarity_score:\n- State consistency level\n- State similarity percentage\n- Explain implications\n\n---\n\n*üéØ SECTION E: CAREER ACTION BRIEF*\n\nProvide:\n- ‚úÖ Top 3 skills from core_skills\n- ‚úÖ Skill pairs from skill_cooccurrence\n- ‚è≥ Target experience: use peak_demand_year from experience_range_analytics\n- ‚ö†Ô∏è Caveats if has_limitations is true\n\n---\n\n_Generated on {{ $now.format('DD-MMM-YYYY HH:mm') }} | {{ $json.total_jobs }} postings analyzed_",
        "options": {
          "systemMessage": "# ROLE DEFINITION\nYou are a Report Narrator for a Job Market Intelligence system.\nYou do NOT calculate. You do NOT analyze. You ONLY narrate data from Python.\n\n# DATA AUTHORITY  \n- raw_analysis is the ONLY source of truth\n- chart_manifest is the ONLY source of truth for charts\n- experience_range_analytics contains range-aware experience insights\n- NEVER invent numbers. Use exact values.\n\n# CHART HANDLING (CRITICAL)\n- Check chart_manifest for each chart_id\n- ONLY say \"chart attached\" if generated: true\n- If generated: false, state the reason\n- Chart 4 (Experience Demand Curve) is NEW - handle it\n\n# EXPERIENCE RANGE ANALYTICS (NEW)\n- If has_range_data is true, use these metrics:\n  - min_experience_observed, max_experience_observed\n  - peak_demand_year, peak_demand_count\n  - dominant_band\n  - experience_flexibility (NARROW/MODERATE/FLEXIBLE)\n- These are MORE granular than bin-based distribution\n\n# STRUCTURAL DISCIPLINE\n- Fixed sections: Data Quality, A, B, C, D, E, Footer\n- No section additions or omissions\n\n# LIMITATION HONESTY\n- State all limitations from the limitations array\n- No softening\n\n# FORMAT\n- Telegram Markdown only: * for bold, _ for italic\n- NO HTML\n- Clean spacing\n\n# FAILURE-SAFE\n- Missing data ‚Üí \"Data unavailable\"\n- NEVER hallucinate"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3.1,
      "position": [368, 96],
      "id": "ai-report-generator",
      "name": "AI Report Generator"
    },
    {
      "parameters": {
        "model": "granite4:3b-h",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [448, 336],
      "id": "ollama-model",
      "name": "Ollama Chat Model",
      "credentials": {
        "ollamaApi": {
          "id": "zfMlbhaLKYrzoQGU",
          "name": "Ollama account"
        }
      }
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [592, 320],
      "id": "96e1aab7-ff37-4809-aad9-d111091ba044",
      "name": "Calculator"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            { "id": "report", "name": "report_text", "value": "={{ $json.output }}", "type": "string" },
            { "id": "chart1", "name": "chart1_base64", "value": "={{ $('Data Processor (Python)').item.json.chart1_base64 }}", "type": "string" },
            { "id": "chart1_caption", "name": "chart1_caption", "value": "={{ $('Data Processor (Python)').item.json.chart1_caption }}", "type": "string" },
            { "id": "chart2", "name": "chart2_base64", "value": "={{ $('Data Processor (Python)').item.json.chart2_base64 }}", "type": "string" },
            { "id": "chart2_caption", "name": "chart2_caption", "value": "={{ $('Data Processor (Python)').item.json.chart2_caption }}", "type": "string" },
            { "id": "chart3", "name": "chart3_base64", "value": "={{ $('Data Processor (Python)').item.json.chart3_base64 }}", "type": "string" },
            { "id": "chart3_caption", "name": "chart3_caption", "value": "={{ $('Data Processor (Python)').item.json.chart3_caption }}", "type": "string" },
            { "id": "chart4", "name": "chart4_base64", "value": "={{ $('Data Processor (Python)').item.json.chart4_base64 }}", "type": "string" },
            { "id": "chart4_caption", "name": "chart4_caption", "value": "={{ $('Data Processor (Python)').item.json.chart4_caption }}", "type": "string" }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [736, 96],
      "id": "prepare-output-node",
      "name": "Prepare Output"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            { "id": "no-data-text", "name": "report_text", "value": "=*üìë JOB MARKET INTELLIGENCE*\n\n*Role:* {{ $('Analysis Trigger').first().json.role_name }}\n\n‚ö†Ô∏è *No data available.*\n\nNo job postings found for this role in your database.\n\n_Run a scrape first using the main Job Market Pipeline._", "type": "string" },
            { "id": "chart1", "name": "chart1_base64", "value": "", "type": "string" },
            { "id": "chart2", "name": "chart2_base64", "value": "", "type": "string" },
            { "id": "chart3", "name": "chart3_base64", "value": "", "type": "string" },
            { "id": "chart4", "name": "chart4_base64", "value": "", "type": "string" }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [336, 576],
      "id": "no-data-node",
      "name": "No Data Report"
    },
    {
      "parameters": {
        "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}",
        "text": "={{ $json.report_text }}",
        "additionalFields": { "appendAttribution": false, "parse_mode": "Markdown" }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [1472, 0],
      "id": "send-report-node",
      "name": "Telegram: Send Report",
      "credentials": {
        "telegramApi": {
          "id": "YgUKoloc6u1XLWhU",
          "name": "job analyst"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [{ "id": "has-chart1", "leftValue": "={{ $json.chart1_base64 }}", "rightValue": "", "operator": { "type": "string", "operation": "notEmpty" }}],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1472, 240],
      "id": "has-chart1-node",
      "name": "Has Chart 1?"
    },
    {
      "parameters": { "operation": "toBinary", "sourceProperty": "chart1_base64", "binaryPropertyName": "chart1", "options": {} },
      "type": "n8n-nodes-base.convertToFile",
      "typeVersion": 1.1,
      "position": [1792, 160],
      "id": "chart1-to-file-node",
      "name": "Chart 1 to File"
    },
    {
      "parameters": {
        "operation": "sendPhoto",
        "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}",
        "binaryData": true,
        "binaryPropertyName": "chart1",
        "additionalFields": { "caption": "={{ $('Prepare Output').item.json.chart1_caption }}", "parse_mode": "Markdown" }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [2016, 160],
      "id": "send-chart1-node",
      "name": "Telegram: Chart 1",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [{ "id": "has-chart2", "leftValue": "={{ $json.chart2_base64 }}", "rightValue": "", "operator": { "type": "string", "operation": "notEmpty" }}],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1472, 400],
      "id": "has-chart2-node",
      "name": "Has Chart 2?"
    },
    {
      "parameters": { "operation": "toBinary", "sourceProperty": "chart2_base64", "binaryPropertyName": "chart2", "options": {} },
      "type": "n8n-nodes-base.convertToFile",
      "typeVersion": 1.1,
      "position": [1792, 320],
      "id": "chart2-to-file-node",
      "name": "Chart 2 to File"
    },
    {
      "parameters": {
        "operation": "sendPhoto",
        "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}",
        "binaryData": true,
        "binaryPropertyName": "chart2",
        "additionalFields": { "caption": "={{ $('Prepare Output').item.json.chart2_caption }}", "parse_mode": "Markdown" }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [2016, 320],
      "id": "send-chart2-node",
      "name": "Telegram: Chart 2",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [{ "id": "has-chart3", "leftValue": "={{ $json.chart3_base64 }}", "rightValue": "", "operator": { "type": "string", "operation": "notEmpty" }}],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1472, 560],
      "id": "has-chart3-node",
      "name": "Has Chart 3?"
    },
    {
      "parameters": { "operation": "toBinary", "sourceProperty": "chart3_base64", "binaryPropertyName": "chart3", "options": {} },
      "type": "n8n-nodes-base.convertToFile",
      "typeVersion": 1.1,
      "position": [1792, 480],
      "id": "chart3-to-file-node",
      "name": "Chart 3 to File"
    },
    {
      "parameters": {
        "operation": "sendPhoto",
        "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}",
        "binaryData": true,
        "binaryPropertyName": "chart3",
        "additionalFields": { "caption": "={{ $('Prepare Output').item.json.chart3_caption }}", "parse_mode": "Markdown" }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [2016, 480],
      "id": "send-chart3-node",
      "name": "Telegram: Chart 3",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [{ "id": "has-chart4", "leftValue": "={{ $json.chart4_base64 }}", "rightValue": "", "operator": { "type": "string", "operation": "notEmpty" }}],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1472, 720],
      "id": "has-chart4-node",
      "name": "Has Chart 4?"
    },
    {
      "parameters": { "operation": "toBinary", "sourceProperty": "chart4_base64", "binaryPropertyName": "chart4", "options": {} },
      "type": "n8n-nodes-base.convertToFile",
      "typeVersion": 1.1,
      "position": [1792, 640],
      "id": "chart4-to-file-node",
      "name": "Chart 4 to File"
    },
    {
      "parameters": {
        "operation": "sendPhoto",
        "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}",
        "binaryData": true,
        "binaryPropertyName": "chart4",
        "additionalFields": { "caption": "={{ $('Prepare Output').item.json.chart4_caption }}", "parse_mode": "Markdown" }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [2016, 640],
      "id": "send-chart4-node",
      "name": "Telegram: Chart 4",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}
    }
  ],
  "connections": {
    "Analysis Trigger": { "main": [[{ "node": "Fetch Job Postings", "type": "main", "index": 0 }]] },
    "Fetch Job Postings": { "main": [[{ "node": "Has Data?", "type": "main", "index": 0 }]] },
    "Has Data?": { "main": [[{ "node": "Data Processor (Python)", "type": "main", "index": 0 }], [{ "node": "No Data Report", "type": "main", "index": 0 }]] },
    "Data Processor (Python)": { "main": [[{ "node": "AI Report Generator", "type": "main", "index": 0 }]] },
    "AI Report Generator": { "main": [[{ "node": "Prepare Output", "type": "main", "index": 0 }]] },
    "Prepare Output": { "main": [[{ "node": "Telegram: Send Report", "type": "main", "index": 0 }, { "node": "Has Chart 1?", "type": "main", "index": 0 }, { "node": "Has Chart 2?", "type": "main", "index": 0 }, { "node": "Has Chart 3?", "type": "main", "index": 0 }, { "node": "Has Chart 4?", "type": "main", "index": 0 }]] },
    "No Data Report": { "main": [[{ "node": "Telegram: Send Report", "type": "main", "index": 0 }]] },
    "Telegram: Send Report": { "main": [[], []] },
    "Has Chart 1?": { "main": [[{ "node": "Chart 1 to File", "type": "main", "index": 0 }], []] },
    "Chart 1 to File": { "main": [[{ "node": "Telegram: Chart 1", "type": "main", "index": 0 }]] },
    "Has Chart 2?": { "main": [[{ "node": "Chart 2 to File", "type": "main", "index": 0 }], []] },
    "Chart 2 to File": { "main": [[{ "node": "Telegram: Chart 2", "type": "main", "index": 0 }]] },
    "Has Chart 3?": { "main": [[{ "node": "Chart 3 to File", "type": "main", "index": 0 }], []] },
    "Chart 3 to File": { "main": [[{ "node": "Telegram: Chart 3", "type": "main", "index": 0 }]] },
    "Has Chart 4?": { "main": [[{ "node": "Chart 4 to File", "type": "main", "index": 0 }], []] },
    "Chart 4 to File": { "main": [[{ "node": "Telegram: Chart 4", "type": "main", "index": 0 }]] },
    "Ollama Chat Model": { "ai_languageModel": [[{ "node": "AI Report Generator", "type": "ai_languageModel", "index": 0 }]] },
    "Calculator": { "ai_tool": [[{ "node": "AI Report Generator", "type": "ai_tool", "index": 0 }]] }
  },
  "settings": { "executionOrder": "v1", "callerPolicy": "workflowsFromSameOwner" },
  "staticData": null
}

{
  "name": "Job Market Analysis Engine",
  "nodes": [
    {
      "parameters": {
        "workflowInputs": {
          "values": [
            { "name": "telegram_chat_id", "type": "number" },
            { "name": "role_name" }
          ]
        }
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [-688, 224],
      "id": "trigger-node",
      "name": "Analysis Trigger"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT * FROM job_postings WHERE chat_id = {{ $json.telegram_chat_id }} AND role = '{{ $json.role_name }}' ORDER BY scraped_date DESC;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [-464, 224],
      "id": "fetch-jobs-node",
      "name": "Fetch Job Postings",
      "credentials": {
        "postgres": {
          "id": "huv0oVp6gAOYZofK",
          "name": "job_market_intelligence"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [
            {
              "id": "check-data-exists",
              "leftValue": "={{ $input.all().length }}",
              "rightValue": 0,
              "operator": { "type": "number", "operation": "gt" }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [-240, 224],
      "id": "data-check-node",
      "name": "Has Data?"
    },
    {
      "parameters": {
        "language": "pythonNative",
        "pythonCode": "import pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\nimport io\nimport base64\nimport re\nfrom collections import Counter\nfrom itertools import combinations\nimport json\n\njobs = _items\nif not jobs:\n    empty_manifest = [\n        {\"chart_id\": \"chart_1\", \"chart_name\": \"Skill Demand\", \"chart_type\": \"Horizontal Bar\", \"generated\": False, \"reason\": \"No data\"},\n        {\"chart_id\": \"chart_2\", \"chart_name\": \"Experience Distribution\", \"chart_type\": \"Bar\", \"generated\": False, \"reason\": \"No data\"},\n        {\"chart_id\": \"chart_3\", \"chart_name\": \"Skill Category Distribution\", \"chart_type\": \"Pie\", \"generated\": False, \"reason\": \"No data\"},\n        {\"chart_id\": \"chart_4\", \"chart_name\": \"Experience Demand Curve\", \"chart_type\": \"Area\", \"generated\": False, \"reason\": \"No data\"}\n    ]\n    return [{'error': 'No job data', 'has_data': False, 'chart1_base64': '', 'chart2_base64': '', 'chart3_base64': '', 'chart4_base64': '', 'chart1_caption': '', 'chart2_caption': '', 'chart3_caption': '', 'chart4_caption': '', 'raw_analysis': '{}', 'chart_manifest': json.dumps(empty_manifest)}]\n\nrecords = [item.get('json', item) if isinstance(item, dict) else item for item in jobs]\ndf = pd.DataFrame(records)\n\nif 'job_id' in df.columns:\n    original_count = len(df)\n    df = df.drop_duplicates(subset=['job_id'])\n    duplicates_removed = original_count - len(df)\nelse:\n    duplicates_removed = 0\n\ntotal_jobs = len(df)\nrole_name = df['role'].iloc[0] if 'role' in df.columns and len(df) > 0 else 'Unknown Role'\n\nSKILL_NORMALIZATION = {\n    'powerbi': 'Power BI', 'power bi': 'Power BI', 'pbi': 'Power BI',\n    'postgres': 'PostgreSQL', 'postgresql': 'PostgreSQL',\n    'gcp': 'GCP', 'google cloud': 'GCP', 'aws': 'AWS', 'azure': 'Azure',\n    'sql': 'SQL', 'mysql': 'MySQL', 'python': 'Python', 'java': 'Java',\n    'javascript': 'JavaScript', 'js': 'JavaScript',\n    'excel': 'Excel', 'tableau': 'Tableau',\n    'machine learning': 'Machine Learning', 'ml': 'Machine Learning',\n    'ai': 'AI', 'data science': 'Data Science',\n    'data analysis': 'Data Analysis', 'etl': 'ETL',\n    'agile': 'Agile', 'scrum': 'Scrum', 'jira': 'Jira',\n    'docker': 'Docker', 'kubernetes': 'Kubernetes',\n    'git': 'Git', 'spark': 'Spark', 'hadoop': 'Hadoop',\n    'salesforce': 'Salesforce', 'sap': 'SAP', 'erp': 'ERP',\n    'project management': 'Project Management',\n    'communication': 'Communication', 'management': 'Management',\n    'design': 'Design', 'operations': 'Operations'\n}\n\nSKILL_CATEGORIES = {\n    'Technical / Programming': ['Python', 'Java', 'JavaScript', 'SQL', 'MySQL', 'PostgreSQL', 'Git'],\n    'Data & Analytics': ['Data Analysis', 'Data Science', 'Machine Learning', 'AI', 'ETL', 'Spark', 'Hadoop'],\n    'Cloud & Infrastructure': ['AWS', 'Azure', 'GCP', 'Docker', 'Kubernetes'],\n    'Business / Process': ['Project Management', 'Operations', 'Management'],\n    'Tools & Platforms': ['Excel', 'Tableau', 'Power BI', 'Jira', 'Salesforce', 'SAP', 'ERP'],\n    'Soft / Collaboration': ['Communication', 'Agile', 'Scrum', 'Design']\n}\n\ndef get_skill_category(skill):\n    for cat, skills in SKILL_CATEGORIES.items():\n        if skill in skills:\n            return cat\n    return 'Other'\n\nknown_skills = list(set(SKILL_NORMALIZATION.keys()))\n\ndef parse_skills(skill_string):\n    if pd.isna(skill_string) or not str(skill_string).strip():\n        return []\n    s = str(skill_string).lower().strip()\n    found = []\n    for skill in sorted(known_skills, key=len, reverse=True):\n        if skill in s:\n            norm = SKILL_NORMALIZATION.get(skill, skill.title())\n            if norm not in found:\n                found.append(norm)\n            s = s.replace(skill, ' ')\n    leftover = [w.strip() for w in s.split() if len(w.strip()) > 3 and w.strip() not in ['yrs', 'years', 'the', 'and', 'for', 'with']]\n    for word in leftover[:3]:\n        if word.title() not in found:\n            found.append(word.title())\n    return found\n\ndef parse_experience_range(exp_str):\n    \"\"\"Parse '3-5 Yrs' into (3, 5)\"\"\"\n    if pd.isna(exp_str) or not str(exp_str).strip():\n        return None\n    s = str(exp_str).strip()\n    # Match: 3-5, 3 - 5, 3-5 Yrs, etc.\n    match = re.search(r'(\\d+)\\s*[-\\u2013]\\s*(\\d+)', s)\n    if match:\n        min_exp = int(match.group(1))\n        max_exp = int(match.group(2))\n        if max_exp < min_exp:\n            min_exp, max_exp = max_exp, min_exp\n        return (min_exp, min(max_exp, 25))\n    # Single value: 5 Yrs, 5+\n    match = re.search(r'(\\d+)', s)\n    if match:\n        val = int(match.group(1))\n        if '+' in s:\n            return (val, min(val + 5, 25))\n        return (val, val)\n    return None\n\ndef parse_experience_midpoint(exp_str):\n    \"\"\"Get midpoint for binning\"\"\"\n    rng = parse_experience_range(exp_str)\n    if rng:\n        return (rng[0] + rng[1]) / 2\n    return None\n\n# Data Quality\ndata_quality = {\n    'total_raw': len(records), 'total_unique': total_jobs, 'duplicates_removed': duplicates_removed,\n    'has_description': int(df['description'].notna().sum()),\n    'has_skills': int(df['skills'].notna().sum()),\n    'has_experience': int(df['experience'].notna().sum()),\n    'has_salary': int((df['salary'].notna() & (df['salary'] != '')).sum()) if 'salary' in df.columns else 0,\n    'companies_count': int(df['company'].nunique()) if 'company' in df.columns else 0,\n    'locations_count': int(df['location'].nunique()) if 'location' in df.columns else 0\n}\ndata_quality['completeness'] = round((data_quality['has_description'] + data_quality['has_skills'] + data_quality['has_experience']) / (total_jobs * 3) * 100, 1) if total_jobs > 0 else 0\n\nif total_jobs >= 20 and data_quality['completeness'] >= 80:\n    quality_grade, quality_desc = \"HIGH\", \"Robust dataset\"\nelif total_jobs >= 10 and data_quality['completeness'] >= 60:\n    quality_grade, quality_desc = \"MEDIUM\", \"Adequate data\"\nelse:\n    quality_grade, quality_desc = \"LOW\", \"Limited data\"\n\n# Skills\nall_skills, skills_per_job = [], []\nfor s in df['skills'].dropna():\n    parsed = parse_skills(s)\n    all_skills.extend(parsed)\n    skills_per_job.append(parsed)\n\nskill_counts = Counter(all_skills)\ntop_skills = skill_counts.most_common(15)\ntotal_mentions = sum(skill_counts.values())\ncore_skills = [s for s, c in top_skills[:5]]\nsecondary_skills = [s for s, c in top_skills[5:10]]\n\nskill_dominance = {}\nif total_mentions > 0:\n    t1 = top_skills[0][1] if len(top_skills) >= 1 else 0\n    t3 = sum(c for s, c in top_skills[:3])\n    t5 = sum(c for s, c in top_skills[:5])\n    lt = sum(c for s, c in top_skills[5:])\n    skill_dominance = {\n        'top1_skill': top_skills[0][0] if top_skills else None,\n        'top1_share': round(t1 / total_mentions * 100, 1),\n        'top3_share': round(t3 / total_mentions * 100, 1),\n        'top5_share': round(t5 / total_mentions * 100, 1),\n        'total_unique': len(skill_counts)\n    }\n\ncategory_counts = Counter()\nfor skill, count in skill_counts.items():\n    category_counts[get_skill_category(skill)] += count\ncategory_distribution = {cat: {'count': c, 'pct': round(c / total_mentions * 100, 1)} for cat, c in category_counts.most_common()} if total_mentions > 0 else {}\n\npair_counts = Counter()\nfor job_skills in skills_per_job:\n    if len(job_skills) >= 2:\n        for pair in combinations(sorted(set(job_skills)), 2):\n            pair_counts[pair] += 1\nskill_cooccurrence = [{'pair': f\"{p[0]} + {p[1]}\", 'count': c} for p, c in pair_counts.most_common(5) if c >= 2]\n\n# Experience - Binned\nexp_mids = [parse_experience_midpoint(e) for e in df['experience'].dropna()]\nexp_mids = [e for e in exp_mids if e is not None]\nexp_dist = {}\ndominant_level = \"N/A\"\nif exp_mids:\n    bins = [0, 2, 5, 8, 12, 25]\n    labels = ['0-2 yrs', '3-5 yrs', '6-8 yrs', '9-12 yrs', '12+ yrs']\n    exp_binned = pd.cut(pd.Series(exp_mids), bins=bins, labels=labels, right=True)\n    exp_dist = {str(k): int(v) for k, v in exp_binned.value_counts().items() if v > 0}\n    if exp_dist:\n        dominant_level = max(exp_dist, key=exp_dist.get)\n\n# Experience - Range Analytics\nexp_ranges = [parse_experience_range(e) for e in df['experience'].dropna()]\nexp_ranges = [e for e in exp_ranges if e is not None]\n\nexp_analytics = {'has_data': False, 'count': 0}\nif exp_ranges:\n    exp_analytics['has_data'] = True\n    exp_analytics['count'] = len(exp_ranges)\n    exp_analytics['min_exp'] = min(r[0] for r in exp_ranges)\n    exp_analytics['max_exp'] = max(r[1] for r in exp_ranges)\n    \n    # Year demand density\n    year_demand = Counter()\n    for min_e, max_e in exp_ranges:\n        for yr in range(min_e, min(max_e, 20) + 1):\n            year_demand[yr] += 1\n    exp_analytics['year_density'] = {str(y): c for y, c in sorted(year_demand.items())}\n    \n    if year_demand:\n        peak = max(year_demand, key=year_demand.get)\n        exp_analytics['peak_year'] = peak\n        exp_analytics['peak_count'] = year_demand[peak]\n        if peak <= 2: exp_analytics['band'] = \"Entry (0-2)\"\n        elif peak <= 5: exp_analytics['band'] = \"Early (3-5)\"\n        elif peak <= 8: exp_analytics['band'] = \"Mid (6-8)\"\n        elif peak <= 12: exp_analytics['band'] = \"Senior (9-12)\"\n        else: exp_analytics['band'] = \"Expert (12+)\"\n    \n    widths = [r[1] - r[0] for r in exp_ranges]\n    avg_w = sum(widths) / len(widths)\n    exp_analytics['avg_width'] = round(avg_w, 1)\n    exp_analytics['flexibility'] = \"NARROW\" if avg_w <= 2 else \"MODERATE\" if avg_w <= 5 else \"FLEXIBLE\"\n\n# Role Clarity\ntitles = df['title'].dropna().unique().tolist()[:5]\ncompanies = df['company'].dropna().unique().tolist()[:5]\nlocations = df['location'].dropna().unique().tolist()[:3]\ntitle_clarity = \"HIGH\" if len(titles) <= 2 else \"MEDIUM\" if len(titles) <= 5 else \"LOW\"\n\n# Consistency\nskill_sets = [set(s) for s in skills_per_job if s]\nsimilarity = 0\nif len(skill_sets) > 1:\n    sims = [len(skill_sets[i] & skill_sets[i+1]) / max(len(skill_sets[i] | skill_sets[i+1]), 1) for i in range(len(skill_sets)-1)]\n    similarity = round(np.mean(sims) * 100, 1) if sims else 0\nconsistency = \"HIGH\" if similarity > 40 else \"MEDIUM\" if similarity > 20 else \"LOW\"\n\n# Limitations\nlimitations = []\nif total_jobs < 10: limitations.append(\"Small sample\")\nif data_quality['completeness'] < 60: limitations.append(\"Low completeness\")\nif not exp_analytics['has_data']: limitations.append(\"No experience data\")\n\n# Chart Conditions\ncan_chart = total_jobs >= 3\nc1_ok = can_chart and len(top_skills) >= 3\nc2_ok = can_chart and len(exp_dist) >= 2\nc3_ok = can_chart and len(category_distribution) >= 3\nc4_ok = can_chart and exp_analytics['has_data'] and len(exp_analytics.get('year_density', {})) >= 2\n\nchart_manifest = [\n    {\"chart_id\": \"chart_1\", \"chart_name\": \"Skill Demand\", \"chart_type\": \"Bar\", \"generated\": c1_ok, \"reason\": None if c1_ok else \"Not enough skills\"},\n    {\"chart_id\": \"chart_2\", \"chart_name\": \"Experience Distribution\", \"chart_type\": \"Bar\", \"generated\": c2_ok, \"reason\": None if c2_ok else \"Not enough exp bins\"},\n    {\"chart_id\": \"chart_3\", \"chart_name\": \"Skill Categories\", \"chart_type\": \"Pie\", \"generated\": c3_ok, \"reason\": None if c3_ok else \"Not enough categories\"},\n    {\"chart_id\": \"chart_4\", \"chart_name\": \"Experience Demand Curve\", \"chart_type\": \"Area\", \"generated\": c4_ok, \"reason\": None if c4_ok else \"No range data\"}\n]\n\n# Generate Charts\nc1, c2, c3, c4 = \"\", \"\", \"\", \"\"\nplt.style.use(\"dark_background\")\nbg, txt = \"#0a0e1a\", \"#f0f0f0\"\n\nif c1_ok:\n    fig, ax = plt.subplots(figsize=(10, 6), dpi=120)\n    fig.patch.set_facecolor(bg); ax.set_facecolor(bg)\n    labels = [s[0] for s in top_skills[:10]]\n    vals = [s[1] for s in top_skills[:10]]\n    ax.barh(labels[::-1], vals[::-1], color=plt.cm.viridis(np.linspace(0.3, 0.9, len(labels)))[::-1])\n    ax.set_title(f'Skills - {role_name}', color=txt, fontsize=14, fontweight='bold')\n    ax.tick_params(colors=txt)\n    plt.tight_layout()\n    buf = io.BytesIO(); plt.savefig(buf, format='png', facecolor=bg); buf.seek(0)\n    c1 = base64.b64encode(buf.read()).decode(); buf.close(); plt.close()\n\nif c2_ok:\n    fig, ax = plt.subplots(figsize=(8, 5), dpi=120)\n    fig.patch.set_facecolor(bg); ax.set_facecolor(bg)\n    ax.bar(list(exp_dist.keys()), list(exp_dist.values()), color=['#00d4ff', '#00ff88', '#ffc107', '#ff6b6b', '#b388ff'][:len(exp_dist)])\n    ax.set_title(f'Experience - {role_name}', color=txt, fontsize=14, fontweight='bold')\n    ax.tick_params(colors=txt)\n    plt.tight_layout()\n    buf = io.BytesIO(); plt.savefig(buf, format='png', facecolor=bg); buf.seek(0)\n    c2 = base64.b64encode(buf.read()).decode(); buf.close(); plt.close()\n\nif c3_ok:\n    fig, ax = plt.subplots(figsize=(8, 6), dpi=120)\n    fig.patch.set_facecolor(bg); ax.set_facecolor(bg)\n    cats = list(category_distribution.keys())[:6]\n    vals = [category_distribution[c]['count'] for c in cats]\n    ax.pie(vals, labels=cats, autopct='%1.0f%%', colors=['#00d4ff', '#00ff88', '#ffc107', '#ff6b6b', '#b388ff', '#ff9966'][:len(cats)], textprops={'color': txt})\n    ax.set_title(f'Categories - {role_name}', color=txt, fontsize=14, fontweight='bold')\n    plt.tight_layout()\n    buf = io.BytesIO(); plt.savefig(buf, format='png', facecolor=bg); buf.seek(0)\n    c3 = base64.b64encode(buf.read()).decode(); buf.close(); plt.close()\n\nif c4_ok:\n    fig, ax = plt.subplots(figsize=(10, 5), dpi=120)\n    fig.patch.set_facecolor(bg); ax.set_facecolor(bg)\n    yd = exp_analytics['year_density']\n    yrs = [int(y) for y in yd.keys()]\n    cts = list(yd.values())\n    ax.fill_between(yrs, cts, alpha=0.4, color='#00d4ff')\n    ax.plot(yrs, cts, color='#00d4ff', linewidth=2, marker='o', markersize=5, markerfacecolor='white')\n    pk = exp_analytics.get('peak_year')\n    if pk:\n        ax.scatter([pk], [exp_analytics['peak_count']], s=100, color='#ffc107', zorder=5)\n        ax.annotate(f'Peak: {pk}yr', (pk, exp_analytics['peak_count']), color='#ffc107', fontweight='bold')\n    ax.set_xlabel('Years', color=txt); ax.set_ylabel('Jobs', color=txt)\n    ax.set_title(f'Experience Curve - {role_name}', color=txt, fontsize=14, fontweight='bold')\n    ax.tick_params(colors=txt)\n    plt.tight_layout()\n    buf = io.BytesIO(); plt.savefig(buf, format='png', facecolor=bg); buf.seek(0)\n    c4 = base64.b64encode(buf.read()).decode(); buf.close(); plt.close()\n\nraw_analysis = {\n    'role': role_name, 'jobs': total_jobs, 'quality': quality_grade,\n    'core_skills': core_skills, 'skill_dominance': skill_dominance,\n    'categories': category_distribution, 'cooccurrence': skill_cooccurrence,\n    'exp_dist': exp_dist, 'dominant_exp': dominant_level,\n    'exp_analytics': exp_analytics,\n    'titles': titles, 'companies': companies,\n    'consistency': consistency, 'similarity': similarity,\n    'limitations': limitations\n}\n\nc1_cap = f\"*üìä Skills - {role_name}*\\n_Core: {', '.join(core_skills[:3])}_\" if c1 else \"\"\nc2_cap = f\"*üìà Experience - {role_name}*\\n_Dominant: {dominant_level}_\" if c2 else \"\"\nc3_cap = f\"*üè∑Ô∏è Categories - {role_name}*\" if c3 else \"\"\nc4_cap = f\"*üìâ Experience Curve - {role_name}*\\n_Peak: {exp_analytics.get('peak_year', 'N/A')} yrs | {exp_analytics.get('flexibility', 'N/A')}_\" if c4 else \"\"\n\nreturn [{\n    'raw_analysis': json.dumps(raw_analysis),\n    'chart_manifest': json.dumps(chart_manifest),\n    'role_name': role_name, 'total_jobs': total_jobs,\n    'chart1_base64': c1, 'chart1_caption': c1_cap,\n    'chart2_base64': c2, 'chart2_caption': c2_cap,\n    'chart3_base64': c3, 'chart3_caption': c3_cap,\n    'chart4_base64': c4, 'chart4_caption': c4_cap,\n    'has_data': True\n}]\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [48, 96],
      "id": "data-processor-node",
      "name": "Data Processor (Python)"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=**DATA:**\n{{ $json.raw_analysis }}\n\n**CHARTS:**\n{{ $json.chart_manifest }}\n\n**REPORT FORMAT:**\n\n*üìä DATA QUALITY*\nJobs: [jobs], Quality: [quality]\n\n---\n\n*üìå ROLE CHECK*\nTitles: [titles count]\nCompanies: [companies]\n\n---\n\n*üìä SKILLS*\nTop skill: [top1_skill] at [top1_share]%\nTop 3: [top3_share]%\nCategories: list top 3 from categories\nPairs: list from cooccurrence\n\n_Chart 1: check chart_manifest_\n\n---\n\n*üìà EXPERIENCE*\nIf exp_analytics.has_data:\n- Range: [min_exp] to [max_exp] years\n- Peak demand: [peak_year] years\n- Band: [band]\n- Flexibility: [flexibility]\n\nIf exp_dist exists:\n- Dominant: [dominant_exp]\n\n_Chart 2 & 4: check chart_manifest_\n\n---\n\n*‚öñÔ∏è MARKET*\nConsistency: [consistency] ([similarity]%)\n\n---\n\n*üéØ ACTION*\n- Skills: [core_skills]\n- Target: [peak_year] years or [dominant_exp]\n- Caveats: [limitations]\n\n---\n_{{ $json.total_jobs }} postings | {{ $now.format('DD-MMM-YYYY') }}_",
        "options": {
          "systemMessage": "You narrate job market data. Use ONLY the provided numbers. Never calculate. Check chart_manifest before mentioning charts - only say 'attached' if generated=true. Be concise. Telegram Markdown only."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3.1,
      "position": [368, 96],
      "id": "ai-report-generator",
      "name": "AI Report Generator"
    },
    {
      "parameters": { "model": "granite4:3b-h", "options": {} },
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [448, 336],
      "id": "ollama-model",
      "name": "Ollama Chat Model",
      "credentials": { "ollamaApi": { "id": "zfMlbhaLKYrzoQGU", "name": "Ollama account" }}
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [592, 320],
      "id": "96e1aab7-ff37-4809-aad9-d111091ba044",
      "name": "Calculator"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            { "id": "report", "name": "report_text", "value": "={{ $json.output }}", "type": "string" },
            { "id": "c1", "name": "chart1_base64", "value": "={{ $('Data Processor (Python)').item.json.chart1_base64 }}", "type": "string" },
            { "id": "c1c", "name": "chart1_caption", "value": "={{ $('Data Processor (Python)').item.json.chart1_caption }}", "type": "string" },
            { "id": "c2", "name": "chart2_base64", "value": "={{ $('Data Processor (Python)').item.json.chart2_base64 }}", "type": "string" },
            { "id": "c2c", "name": "chart2_caption", "value": "={{ $('Data Processor (Python)').item.json.chart2_caption }}", "type": "string" },
            { "id": "c3", "name": "chart3_base64", "value": "={{ $('Data Processor (Python)').item.json.chart3_base64 }}", "type": "string" },
            { "id": "c3c", "name": "chart3_caption", "value": "={{ $('Data Processor (Python)').item.json.chart3_caption }}", "type": "string" },
            { "id": "c4", "name": "chart4_base64", "value": "={{ $('Data Processor (Python)').item.json.chart4_base64 }}", "type": "string" },
            { "id": "c4c", "name": "chart4_caption", "value": "={{ $('Data Processor (Python)').item.json.chart4_caption }}", "type": "string" }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [736, 96],
      "id": "prepare-output-node",
      "name": "Prepare Output"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            { "id": "no-data", "name": "report_text", "value": "=*üìë JOB MARKET INTELLIGENCE*\n\n*Role:* {{ $('Analysis Trigger').first().json.role_name }}\n\n‚ö†Ô∏è *No data available.*\n\n_Run a scrape first._", "type": "string" },
            { "id": "c1", "name": "chart1_base64", "value": "", "type": "string" },
            { "id": "c2", "name": "chart2_base64", "value": "", "type": "string" },
            { "id": "c3", "name": "chart3_base64", "value": "", "type": "string" },
            { "id": "c4", "name": "chart4_base64", "value": "", "type": "string" }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [336, 576],
      "id": "no-data-node",
      "name": "No Data Report"
    },
    {
      "parameters": {
        "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}",
        "text": "={{ $json.report_text }}",
        "additionalFields": { "appendAttribution": false, "parse_mode": "Markdown" }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [1472, 0],
      "id": "send-report-node",
      "name": "Telegram: Send Report",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}
    },
    {
      "parameters": {
        "conditions": { "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [{ "id": "c1", "leftValue": "={{ $json.chart1_base64 }}", "rightValue": "", "operator": { "type": "string", "operation": "notEmpty" }}], "combinator": "and" },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1472, 200],
      "id": "has-chart1-node",
      "name": "Has Chart 1?"
    },
    { "parameters": { "operation": "toBinary", "sourceProperty": "chart1_base64", "binaryPropertyName": "chart1", "options": {} },
      "type": "n8n-nodes-base.convertToFile", "typeVersion": 1.1, "position": [1750, 140], "id": "c1f", "name": "Chart 1 File" },
    { "parameters": { "operation": "sendPhoto", "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}", "binaryData": true, "binaryPropertyName": "chart1",
        "additionalFields": { "caption": "={{ $('Prepare Output').item.json.chart1_caption }}", "parse_mode": "Markdown" }},
      "type": "n8n-nodes-base.telegram", "typeVersion": 1.2, "position": [1950, 140], "id": "tc1", "name": "Send Chart 1",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}},
    {
      "parameters": {
        "conditions": { "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [{ "id": "c2", "leftValue": "={{ $json.chart2_base64 }}", "rightValue": "", "operator": { "type": "string", "operation": "notEmpty" }}], "combinator": "and" },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1472, 360],
      "id": "has-chart2-node",
      "name": "Has Chart 2?"
    },
    { "parameters": { "operation": "toBinary", "sourceProperty": "chart2_base64", "binaryPropertyName": "chart2", "options": {} },
      "type": "n8n-nodes-base.convertToFile", "typeVersion": 1.1, "position": [1750, 300], "id": "c2f", "name": "Chart 2 File" },
    { "parameters": { "operation": "sendPhoto", "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}", "binaryData": true, "binaryPropertyName": "chart2",
        "additionalFields": { "caption": "={{ $('Prepare Output').item.json.chart2_caption }}", "parse_mode": "Markdown" }},
      "type": "n8n-nodes-base.telegram", "typeVersion": 1.2, "position": [1950, 300], "id": "tc2", "name": "Send Chart 2",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}},
    {
      "parameters": {
        "conditions": { "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [{ "id": "c3", "leftValue": "={{ $json.chart3_base64 }}", "rightValue": "", "operator": { "type": "string", "operation": "notEmpty" }}], "combinator": "and" },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1472, 520],
      "id": "has-chart3-node",
      "name": "Has Chart 3?"
    },
    { "parameters": { "operation": "toBinary", "sourceProperty": "chart3_base64", "binaryPropertyName": "chart3", "options": {} },
      "type": "n8n-nodes-base.convertToFile", "typeVersion": 1.1, "position": [1750, 460], "id": "c3f", "name": "Chart 3 File" },
    { "parameters": { "operation": "sendPhoto", "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}", "binaryData": true, "binaryPropertyName": "chart3",
        "additionalFields": { "caption": "={{ $('Prepare Output').item.json.chart3_caption }}", "parse_mode": "Markdown" }},
      "type": "n8n-nodes-base.telegram", "typeVersion": 1.2, "position": [1950, 460], "id": "tc3", "name": "Send Chart 3",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}},
    {
      "parameters": {
        "conditions": { "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [{ "id": "c4", "leftValue": "={{ $json.chart4_base64 }}", "rightValue": "", "operator": { "type": "string", "operation": "notEmpty" }}], "combinator": "and" },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1472, 680],
      "id": "has-chart4-node",
      "name": "Has Chart 4?"
    },
    { "parameters": { "operation": "toBinary", "sourceProperty": "chart4_base64", "binaryPropertyName": "chart4", "options": {} },
      "type": "n8n-nodes-base.convertToFile", "typeVersion": 1.1, "position": [1750, 620], "id": "c4f", "name": "Chart 4 File" },
    { "parameters": { "operation": "sendPhoto", "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}", "binaryData": true, "binaryPropertyName": "chart4",
        "additionalFields": { "caption": "={{ $('Prepare Output').item.json.chart4_caption }}", "parse_mode": "Markdown" }},
      "type": "n8n-nodes-base.telegram", "typeVersion": 1.2, "position": [1950, 620], "id": "tc4", "name": "Send Chart 4",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}}
  ],
  "connections": {
    "Analysis Trigger": { "main": [[{ "node": "Fetch Job Postings", "type": "main", "index": 0 }]] },
    "Fetch Job Postings": { "main": [[{ "node": "Has Data?", "type": "main", "index": 0 }]] },
    "Has Data?": { "main": [[{ "node": "Data Processor (Python)", "type": "main", "index": 0 }], [{ "node": "No Data Report", "type": "main", "index": 0 }]] },
    "Data Processor (Python)": { "main": [[{ "node": "AI Report Generator", "type": "main", "index": 0 }]] },
    "AI Report Generator": { "main": [[{ "node": "Prepare Output", "type": "main", "index": 0 }]] },
    "Prepare Output": { "main": [[{ "node": "Telegram: Send Report", "type": "main", "index": 0 }, { "node": "Has Chart 1?", "type": "main", "index": 0 }, { "node": "Has Chart 2?", "type": "main", "index": 0 }, { "node": "Has Chart 3?", "type": "main", "index": 0 }, { "node": "Has Chart 4?", "type": "main", "index": 0 }]] },
    "No Data Report": { "main": [[{ "node": "Telegram: Send Report", "type": "main", "index": 0 }]] },
    "Has Chart 1?": { "main": [[{ "node": "Chart 1 File", "type": "main", "index": 0 }], []] },
    "Chart 1 File": { "main": [[{ "node": "Send Chart 1", "type": "main", "index": 0 }]] },
    "Has Chart 2?": { "main": [[{ "node": "Chart 2 File", "type": "main", "index": 0 }], []] },
    "Chart 2 File": { "main": [[{ "node": "Send Chart 2", "type": "main", "index": 0 }]] },
    "Has Chart 3?": { "main": [[{ "node": "Chart 3 File", "type": "main", "index": 0 }], []] },
    "Chart 3 File": { "main": [[{ "node": "Send Chart 3", "type": "main", "index": 0 }]] },
    "Has Chart 4?": { "main": [[{ "node": "Chart 4 File", "type": "main", "index": 0 }], []] },
    "Chart 4 File": { "main": [[{ "node": "Send Chart 4", "type": "main", "index": 0 }]] },
    "Ollama Chat Model": { "ai_languageModel": [[{ "node": "AI Report Generator", "type": "ai_languageModel", "index": 0 }]] },
    "Calculator": { "ai_tool": [[{ "node": "AI Report Generator", "type": "ai_tool", "index": 0 }]] }
  },
  "settings": { "executionOrder": "v1", "callerPolicy": "workflowsFromSameOwner" }
}

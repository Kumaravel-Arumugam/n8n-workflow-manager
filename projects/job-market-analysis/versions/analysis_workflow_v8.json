{
  "name": "Job Market Analysis Engine",
  "nodes": [
    {
      "parameters": {
        "workflowInputs": {
          "values": [
            { "name": "telegram_chat_id", "type": "number" },
            { "name": "role_name" }
          ]
        }
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [-688, 224],
      "id": "trigger-node",
      "name": "Analysis Trigger"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT * FROM job_postings WHERE chat_id = {{ $json.telegram_chat_id }} AND role = '{{ $json.role_name }}' ORDER BY scraped_date DESC;",
        "options": {}
      },
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [-464, 224],
      "id": "fetch-jobs-node",
      "name": "Fetch Job Postings",
      "credentials": {
        "postgres": {
          "id": "huv0oVp6gAOYZofK",
          "name": "job_market_intelligence"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [
            {
              "id": "check-data-exists",
              "leftValue": "={{ $input.all().length }}",
              "rightValue": 0,
              "operator": { "type": "number", "operation": "gt" }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [-240, 224],
      "id": "data-check-node",
      "name": "Has Data?"
    },
    {
      "parameters": {
        "language": "pythonNative",
        "pythonCode": "import pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\nimport io\nimport base64\nimport re\nfrom collections import Counter\nfrom itertools import combinations\nimport json\n\njobs = _items\nif not jobs:\n    empty_manifest = [\n        {\"chart_id\": \"chart_1\", \"chart_name\": \"Skill Demand\", \"generated\": False, \"reason\": \"No data\"},\n        {\"chart_id\": \"chart_2\", \"chart_name\": \"Experience Distribution\", \"generated\": False, \"reason\": \"No data\"},\n        {\"chart_id\": \"chart_3\", \"chart_name\": \"Skill Categories\", \"generated\": False, \"reason\": \"No data\"},\n        {\"chart_id\": \"chart_4\", \"chart_name\": \"Experience Demand Curve\", \"generated\": False, \"reason\": \"No data\"}\n    ]\n    return [{'error': 'No data', 'has_data': False, 'chart1_base64': '', 'chart2_base64': '', 'chart3_base64': '', 'chart4_base64': '', 'chart1_caption': '', 'chart2_caption': '', 'chart3_caption': '', 'chart4_caption': '', 'raw_analysis': '{}', 'chart_manifest': json.dumps(empty_manifest)}]\n\nrecords = [item.get('json', item) if isinstance(item, dict) else item for item in jobs]\ndf = pd.DataFrame(records)\n\nif 'job_id' in df.columns:\n    orig = len(df)\n    df = df.drop_duplicates(subset=['job_id'])\n    dups = orig - len(df)\nelse:\n    dups = 0\n\ntotal_jobs = len(df)\nrole_name = df['role'].iloc[0] if 'role' in df.columns and len(df) > 0 else 'Unknown Role'\n\nSKILL_NORM = {\n    'powerbi': 'Power BI', 'power bi': 'Power BI', 'pbi': 'Power BI',\n    'postgres': 'PostgreSQL', 'postgresql': 'PostgreSQL',\n    'gcp': 'GCP', 'google cloud': 'GCP', 'aws': 'AWS', 'azure': 'Azure',\n    'sql': 'SQL', 'mysql': 'MySQL', 'python': 'Python', 'java': 'Java',\n    'javascript': 'JavaScript', 'js': 'JavaScript',\n    'excel': 'Excel', 'tableau': 'Tableau',\n    'machine learning': 'Machine Learning', 'ml': 'Machine Learning',\n    'ai': 'AI', 'data science': 'Data Science',\n    'data analysis': 'Data Analysis', 'etl': 'ETL',\n    'agile': 'Agile', 'scrum': 'Scrum', 'jira': 'Jira',\n    'docker': 'Docker', 'kubernetes': 'Kubernetes',\n    'git': 'Git', 'spark': 'Spark', 'hadoop': 'Hadoop',\n    'salesforce': 'Salesforce', 'sap': 'SAP', 'erp': 'ERP',\n    'project management': 'Project Management',\n    'communication': 'Communication', 'management': 'Management',\n    'design': 'Design', 'operations': 'Operations'\n}\n\nSKILL_CATS = {\n    'Technical': ['Python', 'Java', 'JavaScript', 'SQL', 'MySQL', 'PostgreSQL', 'Git'],\n    'Data & Analytics': ['Data Analysis', 'Data Science', 'Machine Learning', 'AI', 'ETL', 'Spark', 'Hadoop'],\n    'Cloud': ['AWS', 'Azure', 'GCP', 'Docker', 'Kubernetes'],\n    'Business': ['Project Management', 'Operations', 'Management'],\n    'Tools': ['Excel', 'Tableau', 'Power BI', 'Jira', 'Salesforce', 'SAP', 'ERP'],\n    'Soft Skills': ['Communication', 'Agile', 'Scrum', 'Design']\n}\n\ndef get_cat(skill):\n    for cat, skills in SKILL_CATS.items():\n        if skill in skills:\n            return cat\n    return 'Other'\n\nknown = list(set(SKILL_NORM.keys()))\n\ndef parse_skills(s):\n    if pd.isna(s) or not str(s).strip():\n        return []\n    txt = str(s).lower().strip()\n    found = []\n    for sk in sorted(known, key=len, reverse=True):\n        if sk in txt:\n            norm = SKILL_NORM.get(sk, sk.title())\n            if norm not in found:\n                found.append(norm)\n            txt = txt.replace(sk, ' ')\n    leftover = [w.strip() for w in txt.split() if len(w.strip()) > 3 and w.strip() not in ['yrs', 'years', 'the', 'and', 'for', 'with']]\n    for w in leftover[:3]:\n        if w.title() not in found:\n            found.append(w.title())\n    return found\n\ndef parse_exp_range(s):\n    if pd.isna(s) or not str(s).strip():\n        return None\n    txt = str(s).strip()\n    m = re.search(r'(\\d+)\\s*[-\\u2013]\\s*(\\d+)', txt)\n    if m:\n        lo, hi = int(m.group(1)), int(m.group(2))\n        if hi < lo: lo, hi = hi, lo\n        return (lo, min(hi, 25))\n    m = re.search(r'(\\d+)', txt)\n    if m:\n        v = int(m.group(1))\n        return (v, min(v + 5, 25)) if '+' in txt else (v, v)\n    return None\n\ndef parse_exp_mid(s):\n    r = parse_exp_range(s)\n    return (r[0] + r[1]) / 2 if r else None\n\n# Data Quality\ndq = {\n    'total_raw': len(records), 'total_unique': total_jobs, 'dups': dups,\n    'has_desc': int(df['description'].notna().sum()),\n    'has_skills': int(df['skills'].notna().sum()),\n    'has_exp': int(df['experience'].notna().sum()),\n    'companies': int(df['company'].nunique()) if 'company' in df.columns else 0,\n    'locations': int(df['location'].nunique()) if 'location' in df.columns else 0\n}\ndq['completeness'] = round((dq['has_desc'] + dq['has_skills'] + dq['has_exp']) / (total_jobs * 3) * 100, 1) if total_jobs > 0 else 0\nquality = \"HIGH\" if total_jobs >= 20 and dq['completeness'] >= 80 else \"MEDIUM\" if total_jobs >= 10 else \"LOW\"\n\n# Skills\nall_skills, skills_per_job = [], []\nfor s in df['skills'].dropna():\n    p = parse_skills(s)\n    all_skills.extend(p)\n    skills_per_job.append(p)\n\nsk_counts = Counter(all_skills)\ntop_sk = sk_counts.most_common(15)\ntotal_mentions = sum(sk_counts.values())\ncore = [s for s, c in top_sk[:5]]\nsecondary = [s for s, c in top_sk[5:10]]\n\nsk_dom = {}\nif total_mentions > 0:\n    t1 = top_sk[0][1] if top_sk else 0\n    t3 = sum(c for s, c in top_sk[:3])\n    t5 = sum(c for s, c in top_sk[:5])\n    sk_dom = {\n        'top1': top_sk[0][0] if top_sk else None,\n        'top1_pct': round(t1 / total_mentions * 100, 1),\n        'top3_pct': round(t3 / total_mentions * 100, 1),\n        'top5_pct': round(t5 / total_mentions * 100, 1),\n        'unique': len(sk_counts)\n    }\n\ncat_counts = Counter()\nfor sk, c in sk_counts.items():\n    cat_counts[get_cat(sk)] += c\ncat_dist = {cat: {'count': c, 'pct': round(c / total_mentions * 100, 1)} for cat, c in cat_counts.most_common()} if total_mentions > 0 else {}\n\npair_counts = Counter()\nfor job_sk in skills_per_job:\n    if len(job_sk) >= 2:\n        for pair in combinations(sorted(set(job_sk)), 2):\n            pair_counts[pair] += 1\ncooc = [{'pair': f\"{p[0]} + {p[1]}\", 'count': c} for p, c in pair_counts.most_common(5) if c >= 2]\n\n# Experience - Binned\nexp_mids = [parse_exp_mid(e) for e in df['experience'].dropna()]\nexp_mids = [e for e in exp_mids if e is not None]\nexp_dist = {}\ndom_level = \"N/A\"\nif exp_mids:\n    bins = [0, 2, 5, 8, 12, 25]\n    labels = ['0-2 yrs', '3-5 yrs', '6-8 yrs', '9-12 yrs', '12+ yrs']\n    binned = pd.cut(pd.Series(exp_mids), bins=bins, labels=labels, right=True)\n    exp_dist = {str(k): int(v) for k, v in binned.value_counts().items() if v > 0}\n    if exp_dist:\n        dom_level = max(exp_dist, key=exp_dist.get)\n\n# Experience - Range Analytics\nexp_ranges = [parse_exp_range(e) for e in df['experience'].dropna()]\nexp_ranges = [e for e in exp_ranges if e is not None]\n\nexp_an = {'has_data': False, 'count': 0}\nif exp_ranges:\n    exp_an['has_data'] = True\n    exp_an['count'] = len(exp_ranges)\n    exp_an['min'] = min(r[0] for r in exp_ranges)\n    exp_an['max'] = max(r[1] for r in exp_ranges)\n    \n    year_dem = Counter()\n    for lo, hi in exp_ranges:\n        for yr in range(lo, min(hi, 20) + 1):\n            year_dem[yr] += 1\n    exp_an['year_density'] = {str(y): c for y, c in sorted(year_dem.items())}\n    \n    if year_dem:\n        pk = max(year_dem, key=year_dem.get)\n        exp_an['peak_year'] = pk\n        exp_an['peak_count'] = year_dem[pk]\n        exp_an['band'] = \"Entry (0-2)\" if pk <= 2 else \"Early (3-5)\" if pk <= 5 else \"Mid (6-8)\" if pk <= 8 else \"Senior (9-12)\" if pk <= 12 else \"Expert (12+)\"\n    \n    widths = [r[1] - r[0] for r in exp_ranges]\n    avg_w = sum(widths) / len(widths)\n    exp_an['avg_width'] = round(avg_w, 1)\n    exp_an['flexibility'] = \"NARROW\" if avg_w <= 2 else \"MODERATE\" if avg_w <= 5 else \"FLEXIBLE\"\n\n# Role Info\ntitles = df['title'].dropna().unique().tolist()[:5]\ncompanies = df['company'].dropna().unique().tolist()[:5]\nlocations = df['location'].dropna().unique().tolist()[:3]\ntitle_clarity = \"HIGH\" if len(titles) <= 2 else \"MEDIUM\" if len(titles) <= 5 else \"LOW\"\n\n# Consistency\nsk_sets = [set(s) for s in skills_per_job if s]\nsimilarity = 0\nif len(sk_sets) > 1:\n    sims = [len(sk_sets[i] & sk_sets[i+1]) / max(len(sk_sets[i] | sk_sets[i+1]), 1) for i in range(len(sk_sets)-1)]\n    similarity = round(np.mean(sims) * 100, 1) if sims else 0\nconsist = \"HIGH\" if similarity > 40 else \"MEDIUM\" if similarity > 20 else \"LOW\"\n\n# Limitations\nlimits = []\nif total_jobs < 10: limits.append(\"Small sample size\")\nif dq['completeness'] < 60: limits.append(\"Low data completeness\")\nif not exp_an['has_data']: limits.append(\"No experience data parsed\")\n\n# Chart Conditions\ncan_chart = total_jobs >= 3\nc1_ok = can_chart and len(top_sk) >= 3\nc2_ok = can_chart and len(exp_dist) >= 2\nc3_ok = can_chart and len(cat_dist) >= 3\nc4_ok = can_chart and exp_an['has_data'] and len(exp_an.get('year_density', {})) >= 2\n\nchart_manifest = [\n    {\"chart_id\": \"chart_1\", \"chart_name\": \"Skill Demand\", \"generated\": c1_ok, \"reason\": None if c1_ok else \"Insufficient skills\"},\n    {\"chart_id\": \"chart_2\", \"chart_name\": \"Experience Distribution\", \"generated\": c2_ok, \"reason\": None if c2_ok else \"Insufficient exp bins\"},\n    {\"chart_id\": \"chart_3\", \"chart_name\": \"Skill Categories\", \"generated\": c3_ok, \"reason\": None if c3_ok else \"Insufficient categories\"},\n    {\"chart_id\": \"chart_4\", \"chart_name\": \"Experience Demand Curve\", \"generated\": c4_ok, \"reason\": None if c4_ok else \"No range data\"}\n]\n\n# Chart Styling\nc1, c2, c3, c4 = \"\", \"\", \"\", \"\"\nplt.style.use(\"dark_background\")\nbg = \"#0d1117\"  # GitHub dark\ntxt = \"#e6edf3\"\ngrid_c = \"#30363d\"\naccent = \"#58a6ff\"\n\nif c1_ok:\n    fig, ax = plt.subplots(figsize=(10, 6), dpi=130)\n    fig.patch.set_facecolor(bg); ax.set_facecolor(bg)\n    labels = [s[0] for s in top_sk[:10]]\n    vals = [s[1] for s in top_sk[:10]]\n    colors = plt.cm.cool(np.linspace(0.2, 0.8, len(labels)))[::-1]\n    bars = ax.barh(labels[::-1], vals[::-1], color=colors, edgecolor='#ffffff', linewidth=0.5)\n    ax.set_xlabel('Frequency', color=txt, fontsize=11, fontweight='bold')\n    ax.set_title(f'Top Skills Demanded', color=txt, fontsize=14, fontweight='bold', pad=15)\n    ax.tick_params(colors=txt, labelsize=10)\n    ax.grid(axis='x', color=grid_c, linestyle='--', linewidth=0.5, alpha=0.5)\n    for bar, val in zip(bars, vals[::-1]):\n        ax.text(bar.get_width() + 0.3, bar.get_y() + bar.get_height()/2, str(val), va='center', color='#ffffff', fontsize=10, fontweight='bold')\n    ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n    ax.spines['bottom'].set_color(grid_c); ax.spines['left'].set_color(grid_c)\n    plt.tight_layout()\n    buf = io.BytesIO(); plt.savefig(buf, format='png', facecolor=bg, dpi=130); buf.seek(0)\n    c1 = base64.b64encode(buf.read()).decode(); buf.close(); plt.close()\n\nif c2_ok:\n    fig, ax = plt.subplots(figsize=(9, 5), dpi=130)\n    fig.patch.set_facecolor(bg); ax.set_facecolor(bg)\n    lbls = list(exp_dist.keys())\n    vals = list(exp_dist.values())\n    colors = ['#39d353', '#26a641', '#006d32', '#0e4429', '#161b22'][:len(lbls)]\n    bars = ax.bar(lbls, vals, color=colors, edgecolor='#ffffff', linewidth=0.8)\n    ax.set_xlabel('Experience Level', color=txt, fontsize=11, fontweight='bold')\n    ax.set_ylabel('Job Postings', color=txt, fontsize=11, fontweight='bold')\n    ax.set_title('Experience Distribution', color=txt, fontsize=14, fontweight='bold', pad=15)\n    ax.tick_params(colors=txt, labelsize=10)\n    ax.grid(axis='y', color=grid_c, linestyle='--', linewidth=0.5, alpha=0.5)\n    for bar, val in zip(bars, vals):\n        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, str(val), ha='center', color='#ffffff', fontsize=11, fontweight='bold')\n    ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n    ax.spines['bottom'].set_color(grid_c); ax.spines['left'].set_color(grid_c)\n    plt.tight_layout()\n    buf = io.BytesIO(); plt.savefig(buf, format='png', facecolor=bg, dpi=130); buf.seek(0)\n    c2 = base64.b64encode(buf.read()).decode(); buf.close(); plt.close()\n\nif c3_ok:\n    fig, ax = plt.subplots(figsize=(8, 6), dpi=130)\n    fig.patch.set_facecolor(bg); ax.set_facecolor(bg)\n    cats = list(cat_dist.keys())[:6]\n    vals = [cat_dist[c]['count'] for c in cats]\n    colors = ['#58a6ff', '#3fb950', '#d29922', '#f85149', '#a371f7', '#8b949e'][:len(cats)]\n    wedges, texts, autotexts = ax.pie(vals, labels=cats, autopct='%1.0f%%', colors=colors, wedgeprops={'edgecolor': '#ffffff', 'linewidth': 1.5}, textprops={'color': txt, 'fontsize': 10, 'fontweight': 'bold'}, pctdistance=0.75)\n    for at in autotexts:\n        at.set_color('#ffffff')\n        at.set_fontweight('bold')\n        at.set_fontsize(11)\n    ax.set_title('Skill Categories', color=txt, fontsize=14, fontweight='bold', pad=15)\n    plt.tight_layout()\n    buf = io.BytesIO(); plt.savefig(buf, format='png', facecolor=bg, dpi=130); buf.seek(0)\n    c3 = base64.b64encode(buf.read()).decode(); buf.close(); plt.close()\n\nif c4_ok:\n    fig, ax = plt.subplots(figsize=(11, 5), dpi=130)\n    fig.patch.set_facecolor(bg); ax.set_facecolor(bg)\n    yd = exp_an['year_density']\n    yrs = [int(y) for y in yd.keys()]\n    cts = list(yd.values())\n    ax.fill_between(yrs, cts, alpha=0.3, color=accent)\n    ax.plot(yrs, cts, color=accent, linewidth=2.5, marker='o', markersize=6, markerfacecolor='#ffffff', markeredgecolor=accent, markeredgewidth=2)\n    pk = exp_an.get('peak_year')\n    if pk and pk in yrs:\n        pk_ct = exp_an['peak_count']\n        ax.scatter([pk], [pk_ct], s=180, color='#ffc107', zorder=5, edgecolor='#ffffff', linewidth=2)\n        # Offset annotation to avoid overlap\n        x_off = 1.5 if pk < max(yrs) - 2 else -2\n        y_off = pk_ct * 0.15\n        ax.annotate(f'Peak: {pk} yrs ({pk_ct} jobs)', xy=(pk, pk_ct), xytext=(pk + x_off, pk_ct + y_off),\n                    fontsize=10, color='#ffc107', fontweight='bold', ha='left',\n                    arrowprops=dict(arrowstyle='->', color='#ffc107', lw=1.5),\n                    bbox=dict(boxstyle='round,pad=0.3', facecolor=bg, edgecolor='#ffc107', alpha=0.9))\n    ax.set_xlabel('Years of Experience', color=txt, fontsize=11, fontweight='bold')\n    ax.set_ylabel('Jobs Covering This Year', color=txt, fontsize=11, fontweight='bold')\n    ax.set_title('Experience Demand Curve', color=txt, fontsize=14, fontweight='bold', pad=15)\n    ax.tick_params(colors=txt, labelsize=10)\n    ax.grid(axis='both', color=grid_c, linestyle='--', linewidth=0.5, alpha=0.5)\n    ax.set_xlim(min(yrs) - 0.5, max(yrs) + 0.5)\n    ax.set_ylim(0, max(cts) * 1.25)\n    ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n    ax.spines['bottom'].set_color(grid_c); ax.spines['left'].set_color(grid_c)\n    plt.tight_layout()\n    buf = io.BytesIO(); plt.savefig(buf, format='png', facecolor=bg, dpi=130); buf.seek(0)\n    c4 = base64.b64encode(buf.read()).decode(); buf.close(); plt.close()\n\nraw = {\n    'role': role_name, 'jobs': total_jobs, 'quality': quality, 'completeness': dq['completeness'],\n    'titles': titles, 'companies': companies, 'locations': locations,\n    'core_skills': core, 'secondary_skills': secondary, 'skill_dom': sk_dom,\n    'categories': cat_dist, 'cooccurrence': cooc,\n    'exp_dist': exp_dist, 'dom_exp': dom_level, 'exp_analytics': exp_an,\n    'consistency': consist, 'similarity': similarity, 'limitations': limits\n}\n\n# Detailed Captions with Input Parameters\nskills_list = ', '.join(core[:3])\ncats_list = ', '.join(list(cat_dist.keys())[:3])\n\nc1_cap = f\"\"\"*üìä SKILLS ANALYSIS*\n\n*Role:* {role_name}\n*Sample:* {total_jobs} job postings\n*Skills Tracked:* {len(sk_counts)} unique\n\n*Top Skills:* {skills_list}\n*What this means:* These skills appear most frequently in job descriptions. Prioritize learning these first.\"\"\"\n\nc2_cap = f\"\"\"*üìà EXPERIENCE DISTRIBUTION*\n\n*Role:* {role_name}\n*Data Points:* {len(exp_mids)} postings with experience data\n\n*Dominant Level:* {dom_level}\n*What this means:* Most hiring demand is for {dom_level} experience. Target this range for best opportunities.\"\"\"\n\nc3_cap = f\"\"\"*üè∑Ô∏è SKILL CATEGORIES*\n\n*Role:* {role_name}\n*Categories:* {cats_list}\n\n*What this means:* Shows the type of skills (Technical, Business, Soft Skills etc.) most valued for this role.\"\"\"\n\nexp_range_str = f\"{exp_an.get('min', 'N/A')}-{exp_an.get('max', 'N/A')} years\" if exp_an['has_data'] else \"N/A\"\nc4_cap = f\"\"\"*üìâ EXPERIENCE DEMAND CURVE*\n\n*Role:* {role_name}\n*Experience Range:* {exp_range_str}\n*Peak Demand:* {exp_an.get('peak_year', 'N/A')} years ({exp_an.get('peak_count', 0)} jobs)\n*Flexibility:* {exp_an.get('flexibility', 'N/A')}\n\n*What this means:* The curve shows which experience levels have the most job openings. Peak indicates the sweet spot.\"\"\" if c4 else \"\"\n\nreturn [{\n    'raw_analysis': json.dumps(raw),\n    'chart_manifest': json.dumps(chart_manifest),\n    'role_name': role_name, 'total_jobs': total_jobs,\n    'chart1_base64': c1, 'chart1_caption': c1_cap if c1 else '',\n    'chart2_base64': c2, 'chart2_caption': c2_cap if c2 else '',\n    'chart3_base64': c3, 'chart3_caption': c3_cap if c3 else '',\n    'chart4_base64': c4, 'chart4_caption': c4_cap,\n    'has_data': True\n}]\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [48, 96],
      "id": "data-processor-node",
      "name": "Data Processor (Python)"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=**JOB DATA (USE EXACTLY):**\n{{ $json.raw_analysis }}\n\n**CHART STATUS:**\n{{ $json.chart_manifest }}\n\nWrite a Telegram report. CRITICAL: The role name is the 'role' field, NOT the 'titles' array!\n\n*üìë JOB MARKET REPORT*\n*Role:* [use exact 'role' field value]\n\n---\n\n*üìä DATA QUALITY*\n‚Ä¢ [jobs] unique postings\n‚Ä¢ Completeness: [completeness]%\n‚Ä¢ Quality: [quality]\n\n---\n\n*üìå MARKET OVERVIEW*\n*Companies:* [list from companies array]\n*Locations:* [list from locations array]\n*Title variations:* [list from titles array]\n\n---\n\n*üìä SKILLS*\n‚Ä¢ Top: [skill_dom.top1] at [skill_dom.top1_pct]%\n‚Ä¢ Top 3 cover [skill_dom.top3_pct]%\n‚Ä¢ [skill_dom.unique] unique skills\n*Core:* [core_skills]\n*Pairs:* [cooccurrence pairs]\n\n_Chart attached if generated=true in manifest_\n\n---\n\n*üìà EXPERIENCE*\n‚Ä¢ Range: [exp_analytics.min]-[exp_analytics.max] years\n‚Ä¢ Peak: [exp_analytics.peak_year] years ([exp_analytics.peak_count] jobs)\n‚Ä¢ Band: [exp_analytics.band]\n‚Ä¢ Flexibility: [exp_analytics.flexibility]\n‚Ä¢ Dominant: [dom_exp]\n\n_Charts attached if generated=true_\n\n---\n\n*‚öñÔ∏è CONSISTENCY*\n[consistency] ([similarity]%)\n\n---\n\n*üéØ ACTION*\n‚Ä¢ Skills: [core_skills top 3]\n‚Ä¢ Experience: [exp_analytics.peak_year] years\n‚Ä¢ Combos: [top 2 cooccurrence]\n‚Ä¢ Limits: [limitations or 'None']\n\n---\n_{{ $now.format('DD-MMM-YYYY') }} | {{ $json.total_jobs }} jobs_",
        "options": {
          "systemMessage": "You are a report formatter. Use EXACT values from raw_analysis JSON. The 'role' field is the job role - NOT titles. Never invent. Telegram Markdown only (*bold* _italic_). Be concise."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3.1,
      "position": [368, 96],
      "id": "ai-report-generator",
      "name": "AI Report Generator"
    },
    {
      "parameters": { "model": "granite4:3b-h", "options": {} },
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [448, 336],
      "id": "ollama-model",
      "name": "Ollama Chat Model",
      "credentials": { "ollamaApi": { "id": "zfMlbhaLKYrzoQGU", "name": "Ollama account" }}
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [592, 320],
      "id": "96e1aab7-ff37-4809-aad9-d111091ba044",
      "name": "Calculator"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            { "id": "report", "name": "report_text", "value": "={{ $json.output }}", "type": "string" },
            { "id": "c1", "name": "chart1_base64", "value": "={{ $('Data Processor (Python)').item.json.chart1_base64 }}", "type": "string" },
            { "id": "c1c", "name": "chart1_caption", "value": "={{ $('Data Processor (Python)').item.json.chart1_caption }}", "type": "string" },
            { "id": "c2", "name": "chart2_base64", "value": "={{ $('Data Processor (Python)').item.json.chart2_base64 }}", "type": "string" },
            { "id": "c2c", "name": "chart2_caption", "value": "={{ $('Data Processor (Python)').item.json.chart2_caption }}", "type": "string" },
            { "id": "c3", "name": "chart3_base64", "value": "={{ $('Data Processor (Python)').item.json.chart3_base64 }}", "type": "string" },
            { "id": "c3c", "name": "chart3_caption", "value": "={{ $('Data Processor (Python)').item.json.chart3_caption }}", "type": "string" },
            { "id": "c4", "name": "chart4_base64", "value": "={{ $('Data Processor (Python)').item.json.chart4_base64 }}", "type": "string" },
            { "id": "c4c", "name": "chart4_caption", "value": "={{ $('Data Processor (Python)').item.json.chart4_caption }}", "type": "string" }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [736, 96],
      "id": "prepare-output-node",
      "name": "Prepare Output"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            { "id": "no-data", "name": "report_text", "value": "=*üìë JOB MARKET INTELLIGENCE*\n\n*Role:* {{ $('Analysis Trigger').first().json.role_name }}\n\n‚ö†Ô∏è *No data available.*\n\n_Run a scrape first._", "type": "string" },
            { "id": "c1", "name": "chart1_base64", "value": "", "type": "string" },
            { "id": "c2", "name": "chart2_base64", "value": "", "type": "string" },
            { "id": "c3", "name": "chart3_base64", "value": "", "type": "string" },
            { "id": "c4", "name": "chart4_base64", "value": "", "type": "string" }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [336, 576],
      "id": "no-data-node",
      "name": "No Data Report"
    },
    {
      "parameters": {
        "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}",
        "text": "={{ $json.report_text }}",
        "additionalFields": { "appendAttribution": false, "parse_mode": "Markdown" }
      },
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [1472, 0],
      "id": "send-report-node",
      "name": "Telegram: Send Report",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}
    },
    {
      "parameters": {
        "conditions": { "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [{ "id": "c1", "leftValue": "={{ $json.chart1_base64 }}", "rightValue": "", "operator": { "type": "string", "operation": "notEmpty" }}], "combinator": "and" },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1472, 200],
      "id": "has-chart1-node",
      "name": "Has Chart 1?"
    },
    { "parameters": { "operation": "toBinary", "sourceProperty": "chart1_base64", "binaryPropertyName": "chart1", "options": {} },
      "type": "n8n-nodes-base.convertToFile", "typeVersion": 1.1, "position": [1750, 140], "id": "c1f", "name": "Chart 1 File" },
    { "parameters": { "operation": "sendPhoto", "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}", "binaryData": true, "binaryPropertyName": "chart1",
        "additionalFields": { "caption": "={{ $('Prepare Output').item.json.chart1_caption }}", "parse_mode": "Markdown" }},
      "type": "n8n-nodes-base.telegram", "typeVersion": 1.2, "position": [1950, 140], "id": "tc1", "name": "Send Chart 1",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}},
    {
      "parameters": {
        "conditions": { "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [{ "id": "c2", "leftValue": "={{ $json.chart2_base64 }}", "rightValue": "", "operator": { "type": "string", "operation": "notEmpty" }}], "combinator": "and" },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1472, 360],
      "id": "has-chart2-node",
      "name": "Has Chart 2?"
    },
    { "parameters": { "operation": "toBinary", "sourceProperty": "chart2_base64", "binaryPropertyName": "chart2", "options": {} },
      "type": "n8n-nodes-base.convertToFile", "typeVersion": 1.1, "position": [1750, 300], "id": "c2f", "name": "Chart 2 File" },
    { "parameters": { "operation": "sendPhoto", "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}", "binaryData": true, "binaryPropertyName": "chart2",
        "additionalFields": { "caption": "={{ $('Prepare Output').item.json.chart2_caption }}", "parse_mode": "Markdown" }},
      "type": "n8n-nodes-base.telegram", "typeVersion": 1.2, "position": [1950, 300], "id": "tc2", "name": "Send Chart 2",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}},
    {
      "parameters": {
        "conditions": { "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [{ "id": "c3", "leftValue": "={{ $json.chart3_base64 }}", "rightValue": "", "operator": { "type": "string", "operation": "notEmpty" }}], "combinator": "and" },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1472, 520],
      "id": "has-chart3-node",
      "name": "Has Chart 3?"
    },
    { "parameters": { "operation": "toBinary", "sourceProperty": "chart3_base64", "binaryPropertyName": "chart3", "options": {} },
      "type": "n8n-nodes-base.convertToFile", "typeVersion": 1.1, "position": [1750, 460], "id": "c3f", "name": "Chart 3 File" },
    { "parameters": { "operation": "sendPhoto", "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}", "binaryData": true, "binaryPropertyName": "chart3",
        "additionalFields": { "caption": "={{ $('Prepare Output').item.json.chart3_caption }}", "parse_mode": "Markdown" }},
      "type": "n8n-nodes-base.telegram", "typeVersion": 1.2, "position": [1950, 460], "id": "tc3", "name": "Send Chart 3",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}},
    {
      "parameters": {
        "conditions": { "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 2 },
          "conditions": [{ "id": "c4", "leftValue": "={{ $json.chart4_base64 }}", "rightValue": "", "operator": { "type": "string", "operation": "notEmpty" }}], "combinator": "and" },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1472, 680],
      "id": "has-chart4-node",
      "name": "Has Chart 4?"
    },
    { "parameters": { "operation": "toBinary", "sourceProperty": "chart4_base64", "binaryPropertyName": "chart4", "options": {} },
      "type": "n8n-nodes-base.convertToFile", "typeVersion": 1.1, "position": [1750, 620], "id": "c4f", "name": "Chart 4 File" },
    { "parameters": { "operation": "sendPhoto", "chatId": "={{ $('Analysis Trigger').first().json.telegram_chat_id }}", "binaryData": true, "binaryPropertyName": "chart4",
        "additionalFields": { "caption": "={{ $('Prepare Output').item.json.chart4_caption }}", "parse_mode": "Markdown" }},
      "type": "n8n-nodes-base.telegram", "typeVersion": 1.2, "position": [1950, 620], "id": "tc4", "name": "Send Chart 4",
      "credentials": { "telegramApi": { "id": "YgUKoloc6u1XLWhU", "name": "job analyst" }}}
  ],
  "connections": {
    "Analysis Trigger": { "main": [[{ "node": "Fetch Job Postings", "type": "main", "index": 0 }]] },
    "Fetch Job Postings": { "main": [[{ "node": "Has Data?", "type": "main", "index": 0 }]] },
    "Has Data?": { "main": [[{ "node": "Data Processor (Python)", "type": "main", "index": 0 }], [{ "node": "No Data Report", "type": "main", "index": 0 }]] },
    "Data Processor (Python)": { "main": [[{ "node": "AI Report Generator", "type": "main", "index": 0 }]] },
    "AI Report Generator": { "main": [[{ "node": "Prepare Output", "type": "main", "index": 0 }]] },
    "Prepare Output": { "main": [[{ "node": "Telegram: Send Report", "type": "main", "index": 0 }, { "node": "Has Chart 1?", "type": "main", "index": 0 }, { "node": "Has Chart 2?", "type": "main", "index": 0 }, { "node": "Has Chart 3?", "type": "main", "index": 0 }, { "node": "Has Chart 4?", "type": "main", "index": 0 }]] },
    "No Data Report": { "main": [[{ "node": "Telegram: Send Report", "type": "main", "index": 0 }]] },
    "Has Chart 1?": { "main": [[{ "node": "Chart 1 File", "type": "main", "index": 0 }], []] },
    "Chart 1 File": { "main": [[{ "node": "Send Chart 1", "type": "main", "index": 0 }]] },
    "Has Chart 2?": { "main": [[{ "node": "Chart 2 File", "type": "main", "index": 0 }], []] },
    "Chart 2 File": { "main": [[{ "node": "Send Chart 2", "type": "main", "index": 0 }]] },
    "Has Chart 3?": { "main": [[{ "node": "Chart 3 File", "type": "main", "index": 0 }], []] },
    "Chart 3 File": { "main": [[{ "node": "Send Chart 3", "type": "main", "index": 0 }]] },
    "Has Chart 4?": { "main": [[{ "node": "Chart 4 File", "type": "main", "index": 0 }], []] },
    "Chart 4 File": { "main": [[{ "node": "Send Chart 4", "type": "main", "index": 0 }]] },
    "Ollama Chat Model": { "ai_languageModel": [[{ "node": "AI Report Generator", "type": "ai_languageModel", "index": 0 }]] },
    "Calculator": { "ai_tool": [[{ "node": "AI Report Generator", "type": "ai_tool", "index": 0 }]] }
  },
  "settings": { "executionOrder": "v1", "callerPolicy": "workflowsFromSameOwner" }
}
